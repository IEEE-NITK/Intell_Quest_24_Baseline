{
    "abstract": "In this paper, we consider wireless positioning using Received Signal Strength (RSS) fingerprinting. To obtain good accuracy, this technique requires a database containing a high density of up-to-date fingerprints. However, as acquiring fingerprints through training is labor intensive and the indoor topology is subject to changes, a high density fingerprint database cannot always be obtained. On t...",
    "articleNumber": "8825770",
    "articleTitle": "How to Get the Best Out of Your Fingerprint Database: Hierarchical Fingerprint Indoor Positioning for Databases With Variable Density",
    "authors": [
        {
            "preferredName": "Qiang Chang",
            "normalizedName": "Q. Chang",
            "firstName": "Qiang",
            "lastName": "Chang",
            "searchablePreferredName": "Qiang Chang",
            "id": 37089599264
        },
        {
            "preferredName": "Samuel Van De Velde",
            "normalizedName": "S. Van De Velde",
            "firstName": "Samuel",
            "lastName": "Van De Velde",
            "searchablePreferredName": "Samuel Van De Velde",
            "id": 38247504700
        },
        {
            "preferredName": "Heidi Steendam",
            "normalizedName": "H. Steendam",
            "firstName": "Heidi",
            "lastName": "Steendam",
            "searchablePreferredName": "Heidi Steendam",
            "id": 37269092200
        }
    ],
    "doi": "10.1109/ACCESS.2019.2939545",
    "publicationTitle": "IEEE Access",
    "publicationYear": "2022",
    "publicationVolume": null,
    "publicationIssue": null,
    "volume": "10",
    "issue": null,
    "documentLink": "/document/8825770/",
    "xml": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<response><accessType>CCBY - IEEE is not the copyright holder of this material. Please follow the instructions via https://creativecommons.org/licenses/by/4.0/ to obtain full-text articles and stipulations in the API documentation.</accessType><div id=\"BodyWrapper\" class=\"ArticlePage\" xmlns:ieee=\"http://www.ieeexplore.ieee.org\"><div id=\"article\">\n<div class=\"section\" id=\"sec1\"><div class=\"header article-hdr\"><div class=\"kicker\">\n                                SECTION I.</div><h2>Introduction</h2></div><p>The existence of an accurate indoor positioning system is a prerequisite for Location Based Services (LBS), which are implemented in an increasingly number of applications. However no accurate large scale positioning system is available yet, due to the lack of infrastructure, the high hardware cost, or the low accuracy of the solutions. One of the most promising low-cost solutions is based on RSS fingerprinting. In this approach, the position is estimated by comparing the Received Signal Strength (RSS) with fingerprints in a database. A fingerprint indoor positioning system consists of two phases. In the first, off-line training phase, a database of position-fingerprints is constructed by inserting for a number of reference points (RPs) with the received signal strength (RSS) from different signal sources, such as WiFi access points <a ref-type=\"bibr\" anchor=\"ref1\" id=\"context_ref_1_1\" data-range=\"ref1\">[1]</a>, FM <a ref-type=\"bibr\" anchor=\"ref2\" id=\"context_ref_2_1\" data-range=\"ref2\">[2]</a>, UWB(ultra wide band) <a ref-type=\"bibr\" anchor=\"ref3\" id=\"context_ref_3_1\" data-range=\"ref3\">[3]</a> and geomagnetic fields <a ref-type=\"bibr\" anchor=\"ref4\" id=\"context_ref_4_1\" data-range=\"ref4\">[4]</a>. In the second, on-line positioning phase, the RSS values from different sources, measured by the user, are compared with the data in the database, and based on the best match, the user\u2019s position is determined. Because of the widespread availability of different signal sources, the deployment cost is low. Further, the algorithms can easily be implemented in mobile devices, and result in a reasonable accuracy. Currently, some commercial fingerprinting implementations are available, such as Google Map Indoor <a ref-type=\"bibr\" anchor=\"ref5\" id=\"context_ref_5_1\" data-range=\"ref5\">[5]</a>, WiFiSlam <a ref-type=\"bibr\" anchor=\"ref6\" id=\"context_ref_6_1\" data-range=\"ref6\">[6]</a> or Rtmap <a ref-type=\"bibr\" anchor=\"ref7\" id=\"context_ref_7_1\" data-range=\"ref7\">[7]</a>.</p><p>The main issue in fingerprint positioning is the requirement of a high-density up-to-date database, as the accuracy of the fingerprinting technique highly depends on the density and accuracy of the fingerprints in the database. Firstly, as constructing and maintaining a high-density database is labor intensive, expensive and sometimes practically impossible, because of the complex local environments, the available databases show diverse training data densities, and sometimes insufficient data for accurate positioning. As point-by-point measurements of the fingerprints is too labor intensive and expensive, alternative solutions to construct and maintain a high-density database were proposed in the literature. The first solution is crowdsourcing <a ref-type=\"bibr\" anchor=\"ref8\" id=\"context_ref_8_1\" data-range=\"ref8\">[8]</a>. In crowdsourcing, the user upload their fingerprints to update the database. However, encouraging the user to upload their data is a challenge. The second solution is creating a virtual database using mathematical model, such as linear and exponential model <a ref-type=\"bibr\" anchor=\"ref9\" id=\"context_ref_9_1\" data-range=\"ref9\">[9]</a>, MotleyKeenan model <a ref-type=\"bibr\" anchor=\"ref10\" id=\"context_ref_10_1\" data-range=\"ref10\">[10]</a>, Log-Distance Path Loss (LDPL) model <a ref-type=\"bibr\" anchor=\"ref11\" id=\"context_ref_11_1\" data-range=\"ref11\">[11]</a>, Gaussian processes (GP) model <a ref-type=\"bibr\" anchor=\"ref12\" id=\"context_ref_12_1\" data-range=\"ref12 ref13 ref14\">[12]</a>\u2013\u200b<a ref-type=\"bibr\" anchor=\"ref14\" id=\"context_ref_14_1\" data-range=\"ref12 ref13 ref14\">[14]</a> and so on. The third way is ray-tracing <a ref-type=\"bibr\" anchor=\"ref15\" id=\"context_ref_15_1\" data-range=\"ref15\">[15]</a>. In ray-tracing, a detailed description of the environment is required to build the fingerprint database. The fourth method is simultaneous localization and mapping (SLAM) <a ref-type=\"bibr\" anchor=\"ref16\" id=\"context_ref_16_1\" data-range=\"ref16\">[16]</a>. In SLAM, the users are equipped with a receiver and an IMU, and the database is populated on the fly. As the developement of deep learning, the researchers are trying to present the use of deep neural networks (DNN) for WiFi fingerprinting <a ref-type=\"bibr\" anchor=\"ref17\" id=\"context_ref_17_1\" data-range=\"ref17 ref18 ref19 ref20\">[17]</a>\u2013\u200b<a ref-type=\"bibr\" anchor=\"ref20\" id=\"context_ref_20_1\" data-range=\"ref17 ref18 ref19 ref20\">[20]</a>. The fingerprint database is replaced by a deep neural network. However, training the deep neural network requires a lot of labeled data.</p><p>The second issue in fingerprint positioning is the time required to search the database, which is related to the centralized nature of the fingerprint position algorithms. Because of the memory required for a dense database, the database is generally stored in a central location server. Every time a user wants to estimate its position, the user first needs to collect accurate measurements of the RSS and submit the measured values to the location server. The server searches the database to find the most likely match, from which the user\u2019s position is derived. As data retrieval from a large database is time-consuming, the users might not receive their results in real time.</p><p>To cope with the issues in fingerprint positioning, we introduce the Hierarchical Positioning Algorithm (HPA), which is based on the Discrete Level of Detail (DLOD) algorithm <a ref-type=\"bibr\" anchor=\"ref21\" id=\"context_ref_21_1\" data-range=\"ref21\">[21]</a> from computer graphics. This HPA algorithm, however, requires the construction of a hierarchical database for the different levels of the algorithm, containing different densities of fingerprints. In order to have the same accuracy over the whole area, the fingerprints in each sub-database of the hierarchical database must have a spatial distribution that is as uniform as possible. For constructing the hierarchical database from the variable density database, we use the Minimum Distance Algorithm (MDA) in order to select the best RPs and the Local Gaussian Process (LGP) algorithm to estimate the RSS values at the selected RPs. Compared with GP, LGP has lower complexity, at the cost of a slight deterioration of the accuracy. The HPA starts with a coarse estimate at the highest level, and gradually improves the accuracy in going to the lowest level. In this paper, we show that the proposed HPA algorithm, with the hierarchical database constructed using LGP and MDA, improves the accuracy in areas with sparse training data, and reduces the time-consumption of the position estimation in dense data areas. To the best knowledge of the authors, this article is the first presenting the use of DLOD for fingerprint positioning.</p><p>The rest of the paper is organized as follows. <a ref-type=\"sec\" anchor=\"sec2\" class=\"fulltext-link\">Section II</a> introduces the hierarchical positioning algorithm, and reviews the MDA and LGP algorithms. <a ref-type=\"sec\" anchor=\"sec3\" class=\"fulltext-link\">Section III</a> provides the simulation results and the conclusions are given in <a ref-type=\"sec\" anchor=\"sec4\" class=\"fulltext-link\">Section IV</a>.</p></div>\n<div class=\"section\" id=\"sec2\"><div class=\"header article-hdr\"><div class=\"kicker\">\n                                SECTION II.</div><h2>The Hierarchical Positioning Algorithm</h2></div><div class=\"section_2\" id=\"sec2a\"><h3>A. System Description</h3><p class=\"has-inline-formula\">In this paper, we concentrate on 2D positioning. Assume the fingerprint database covers an area <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$P$\n</tex-math></inline-formula> of <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$S (m^{2})$\n</tex-math></inline-formula>, and contains fingerprints from <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$a$\n</tex-math></inline-formula> signal sources, such as FM, WiFi, DVB and DTMB. During the training phase, we measure signal strengths at <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$n$\n</tex-math></inline-formula> reference points (RPs) <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$RP_{i}=(x_{i},y_{i}),i=1,2,\\cdots,n$\n</tex-math></inline-formula>, and store the resulting RSS values together with the coordinates. Based on the resulting training database <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB_{tr}$\n</tex-math></inline-formula>, we will estimate a user\u2019s position during the on-line phase.</p><p>In order to reduce the time for searching the database, we propose the Hierarchical Positioning Algorithm (HPA). This algorithm is based on the Discrete Level of Detail (DLOD) algorithm used in computer vision to decrease the complexity of representation of a 3D object when it moves away from the viewer <a ref-type=\"bibr\" anchor=\"ref22\" id=\"context_ref_22_2a\" data-range=\"ref22\">[22]</a>. <a ref-type=\"fig\" anchor=\"fig1\" class=\"fulltext-link\">Figure 1</a> illustrates the basic idea of DLOD.\n<div class=\"figure figure-full\" id=\"fig1\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang1-2939545-large.gif\" data-fig-id=\"fig1\"><img src=\"\" data-src-img=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang1-2939545-small.gif\" alt=\"FIGURE 1. - The basic idea of DLOD.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 1. </b><fig><p>The basic idea of DLOD.</p></fig></div><p class=\"links\"><a href=\"/document/8825770/figures\" class=\"all\">Show All</a></p></div></p><p>In <a ref-type=\"fig\" anchor=\"fig1\" class=\"fulltext-link\">Fig. 1</a>, if we are far from the object, we just need to render level 1, which contains fewer details. When we move closer, then we render one of the four tiles in Level 2 that contains more details according to our view. Using DLOD is a way of decrease the complexity of a 3D object representation.</p><p class=\"has-inline-formula\">In the HPA algorithm, we use a hierarchical database containing different levels. In a high-level sub-database, the area <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$P$\n</tex-math></inline-formula> is sparsely covered with a low density of fingerprints, resulting in a coarse estimate. At a low-level sub-database, the data is dense and results in a fine estimate. <a ref-type=\"fig\" anchor=\"fig2\" class=\"fulltext-link\">Figure 2</a> illustrates a hierarchical database with two levels. Let us denote the database at level <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$k$\n</tex-math></inline-formula> as <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB^{(k)}$\n</tex-math></inline-formula>. We assume database <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB^{(k)}$\n</tex-math></inline-formula> contains <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$n^{(k)}$\n</tex-math></inline-formula> reference points <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$RP^{(k)}_{i}$\n</tex-math></inline-formula>, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$i=1,\\ldots, n^{(k)}$\n</tex-math></inline-formula> with coordinates <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$(x^{(k)}_{i}, y^{(k)}_{i})$\n</tex-math></inline-formula> and RSS values <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\{(RSS^{(k)}_{i,j},\\delta ^{(k)}_{i,j})| j=1,2,\\cdots,a_{i}\\}$\n</tex-math></inline-formula>, where <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$a_{i}$\n</tex-math></inline-formula> is the number of signal sources within <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$RP^{(k)}_{i}$\n</tex-math></inline-formula>\u2019s visibility, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$RSS^{(k)}_{i,j}$\n</tex-math></inline-formula> is the measured signal strength corresponding to signal source <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$j$\n</tex-math></inline-formula> and <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\delta ^{(k)}_{i,j}$\n</tex-math></inline-formula> is the uncertainty on the RSS value. In order to obtain the wanted accuracy over the whole area <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$P$\n</tex-math></inline-formula>, the RPs at each level have to be spatially uniformly distributed. However, the database constructed in the training phase will in practice have variable density, such that extracting the hierarchical database from the training database is not straightforward. In order to build the hierarchical database, we consider the minimum distance algorithm (MDA) to select the RPs as uniformly as possible over the area, and the local Gaussian process (LGP) algorithm to estimate the RSS values for the selected RPs. After the hierarchical database is constructed, we propose an altered version of the K-weighted nearest neighbors (KWNN) algorithm to extract the user\u2019s position from the hierarchical database.\n<div class=\"figure figure-full\" id=\"fig2\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang2-2939545-large.gif\" data-fig-id=\"fig2\"><img src=\"\" data-src-img=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang2-2939545-small.gif\" alt=\"FIGURE 2. - A hierarchical database with two levels.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 2. </b><fig><p>A hierarchical database with two levels.</p></fig></div><p class=\"links\"><a href=\"/document/8825770/figures\" class=\"all\">Show All</a></p></div></p></div><div class=\"section_2\" id=\"sec2b\"><h3>B. Minimum Distance Algorithm</h3><p class=\"has-inline-formula\">The hierarchical fingerprint database consists of several sub-databases with different densities of fingerprints. As stated earlier, the fingerprints in each sub-database should be selected as uniformly as possible over the area <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$P$\n</tex-math></inline-formula>. Define <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$n^{(k)}$\n</tex-math></inline-formula> as the number of reference points to be selected for the database <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB^{(k)}$\n</tex-math></inline-formula> at level <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$k$\n</tex-math></inline-formula>. However, for general values of <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$n^{(k)}$\n</tex-math></inline-formula>, it is not straightforward to uniformly distribute the RPs over the area. Therefore, we propose a low-complexity algorithm to select the positions of the RPs: the Minimum Distance Algorithm (MDA). In this algorithm, the selection of the positions of the RPs of the sub-database at level <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$k$\n</tex-math></inline-formula> is based on a virtual sample database <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB_{v}^{(k)}$\n</tex-math></inline-formula>, which is constructed by placing a square grid in the area <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$P$\n</tex-math></inline-formula> with grid size <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\lambda ^{(k)}$\n</tex-math></inline-formula>, where the positions of the virtual RPs are selected as the corners of the squares in the grid. Assuming the room has size <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$x_{\\max } \\times y_{\\max }$\n</tex-math></inline-formula>, the number of virtual positions equals <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\lfloor \\frac {x_{\\max }}{\\lambda ^{(k)}}$\n</tex-math></inline-formula>, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\rfloor \\cdot \\lfloor \\frac {y_{\\max }}{\\lambda ^{(k)}} \\rfloor $\n</tex-math></inline-formula>. The <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$n^{(k)}$\n</tex-math></inline-formula> positions of the RPs for sub-database <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$k$\n</tex-math></inline-formula> are selected out of the virtual sample database <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB_{v}^{(k)}$\n</tex-math></inline-formula>. We initialize the algorithm by randomly choosing one virtual position <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$RP_{c}$\n</tex-math></inline-formula> from <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB_{v}^{(k)}$\n</tex-math></inline-formula>: <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB^{(k)} =\\{ RP_{c}\\}$\n</tex-math></inline-formula>. The other <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$n^{(k)}-1$\n</tex-math></inline-formula> positions are picked from the virtual database <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB_{v}^{(k)}$\n</tex-math></inline-formula> based on the measure function <disp-formula id=\"deqn1\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} M_{i}= \\sum _{j}{\\frac {1}{(x_{i}-x_{j})^{2} + (y_{i}-y_{j})^{2}}}\\tag{1}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} M_{i}= \\sum _{j}{\\frac {1}{(x_{i}-x_{j})^{2} + (y_{i}-y_{j})^{2}}}\\tag{1}\\end{equation*}\n</span></span></disp-formula> where <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$(x_{i},y_{i})$\n</tex-math></inline-formula> is the coordinate of the candidate position <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\in DB_{v}^{(k)}$\n</tex-math></inline-formula> and <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$(x_{j},y_{j})$\n</tex-math></inline-formula> are the coordinates of the RP positions already present in the sub-database <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB^{(k)}$\n</tex-math></inline-formula>. The virtual position that minimizes <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$M_{i}$\n</tex-math></inline-formula> is selected and added to the database <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB^{(k)}$\n</tex-math></inline-formula>. Because the measure function <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$M_{i}$\n</tex-math></inline-formula> is inversely proportional to the Euclidean distances between the candidate RF and the RPs in the database <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB^{(k)}$\n</tex-math></inline-formula>, candidate positions that are far from the already selected RP positions are favored, while candidate positions near already selected RP positions are filtered out. As a result, the distances between the RPs will be maximized and the RPs in <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB^{(k)}$\n</tex-math></inline-formula> will be distributed uniformly and expand to the very edges of the area <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$P$\n</tex-math></inline-formula>. The algorithm is shown in <a ref-type=\"algorithm\" anchor=\"alg1\" class=\"fulltext-link\">Algorithm 1</a>.<div class=\"algorithm rule-both\" id=\"alg1\"><h3>Algorithm 1 <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$MDA$\n</tex-math></inline-formula></h3><div class=\"alg-item label\"><span class=\"label\">Require:</span><p class=\"has-inline-formula\">the area <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$P$\n</tex-math></inline-formula>, the distance <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\lambda ^{(k)}$\n</tex-math></inline-formula> between neighbor virtual RPs in <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB_{v}^{(k)}$\n</tex-math></inline-formula>, the number <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$n^{(k)}$\n</tex-math></inline-formula> of RPs we want to select.</p></div><div class=\"alg-item label\"><span class=\"label\">Ensure:</span><p class=\"has-inline-formula\">select RPs every <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\lambda ^{(k)}$\n</tex-math></inline-formula> meters in <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$P$\n</tex-math></inline-formula> to build <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB_{v}^{(k)}$\n</tex-math></inline-formula>,</p></div><div class=\"alg-item label\"><span class=\"label\">Ensure:</span><p class=\"has-inline-formula\">randomly select <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$RP_{c}$\n</tex-math></inline-formula> from <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB_{v}^{(k)}$\n</tex-math></inline-formula>, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB^{(k)} = \\{RP_{c}\\}$\n</tex-math></inline-formula></p></div><div class=\"alg-item\"><p class=\"has-inline-formula\"><b>while</b> <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$|DB^{(k)}|\\neq n^{(k)}$\n</tex-math></inline-formula> <b>do</b></p></div><div class=\"alg-item\"><p class=\"has-inline-formula\"><b>for all</b> <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$RP_{i} \\subset DB_{v}^{(k)}$\n</tex-math></inline-formula> <b>do</b></p></div><div class=\"alg-item\"><p class=\"has-inline-formula\">Calculate <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$M_{i}$\n</tex-math></inline-formula> <a ref-type=\"disp-formula\" anchor=\"deqn1\" href=\"#deqn1\" class=\"fulltext-link\">(1)</a></p></div><div class=\"alg-item\"><p><b>end for</b></p></div><div class=\"alg-item\"><p class=\"has-inline-formula\"><inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$RP = \\arg \\min \\limits_{RP_{i} \\in DB_{v}^{(k)}} M_{i}$\n</tex-math></inline-formula></p></div><div class=\"alg-item\"><p class=\"has-inline-formula\"><inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB^{(k)} \\gets RP$\n</tex-math></inline-formula></p></div><div class=\"alg-item\"><p><b>end while</b></p></div></div></p><p class=\"has-inline-formula\">To illustrate MDA, we consider an area <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$P$\n</tex-math></inline-formula> of <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$16.5m \\times 48.5m$\n</tex-math></inline-formula>, and <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\lambda ^{(k)} = 0.5m$\n</tex-math></inline-formula>. <a ref-type=\"fig\" anchor=\"fig3\" class=\"fulltext-link\">Figure 3</a> shows the positions of the RPs in <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB^{(k)}$\n</tex-math></inline-formula> when <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$n^{(k)} = 20$\n</tex-math></inline-formula> and 40 RPs are selected out of the virtual database <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB_{v}^{(k)}$\n</tex-math></inline-formula>. Further, the figure shows the positions of the RPs when the RPs are selected randomly from <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB_{v}^{(k)}$\n</tex-math></inline-formula>. As can be observed, the proposed algorithm is able to select the RPs spatially uniform over the area <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$P$\n</tex-math></inline-formula>.\n<div class=\"figure figure-full\" id=\"fig3\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang3abcd-2939545-large.gif\" data-fig-id=\"fig3\"><img src=\"\" data-src-img=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang3abcd-2939545-small.gif\" alt=\"FIGURE 3. - Positions of the RPs (a) MDA, &#10;$n^{(k)}=20$&#10; (b) MDA, &#10;$n^{(k)}=40$&#10; (c) randomly, &#10;$n^{(k)}=20$&#10; (d) randomly, &#10;$n^{(k)}=40$&#10;.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 3. </b><fig><p class=\"has-inline-formula\">Positions of the RPs (a) MDA, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$n^{(k)}=20$\n</tex-math></inline-formula> (b) MDA, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$n^{(k)}=40$\n</tex-math></inline-formula> (c) randomly, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$n^{(k)}=20$\n</tex-math></inline-formula> (d) randomly, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$n^{(k)}=40$\n</tex-math></inline-formula>.</p></fig></div><p class=\"links\"><a href=\"/document/8825770/figures\" class=\"all\">Show All</a></p></div></p><p class=\"has-inline-formula\">After the positions of the RPs in database <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB^{(k)}$\n</tex-math></inline-formula> are selected with MDA, the RSS values for these RPs need to be determined. To this end, we compare the positions of the RPs in <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB^{(k)}$\n</tex-math></inline-formula> with those in the training database <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB_{tr}$\n</tex-math></inline-formula>. Whenever one or more RPs in <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB_{tr}$\n</tex-math></inline-formula> are within a distance <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\varepsilon ^{(k)}$\n</tex-math></inline-formula> of a RP <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$RP_{i}$\n</tex-math></inline-formula> in <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB^{(k)}$\n</tex-math></inline-formula>, we will replace the position of the RP in <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB^{(k)}$\n</tex-math></inline-formula> with the position of the nearest RP in <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB_{tr}$\n</tex-math></inline-formula>, together with its RSS values and the uncertainty on the measured RSS values. If no RPs in <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB_{tr}$\n</tex-math></inline-formula> are within a distance <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\varepsilon ^{(k)}$\n</tex-math></inline-formula> of a RP <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$RP_{i}$\n</tex-math></inline-formula> in <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB^{(k)}$\n</tex-math></inline-formula>, the Local Gaussian Process (LGP) algorithm will be used to estimate the RSS values and their uncertainty in <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$RP_{i}$\n</tex-math></inline-formula>.</p><p class=\"has-inline-formula\">The resulting sub-database <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB^{(k)}$\n</tex-math></inline-formula> is determined by three parameters: the number <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$n^{(k)}$\n</tex-math></inline-formula> of RPs, the distance <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\lambda ^{(k)}$\n</tex-math></inline-formula> between RPs in the virtual sample database and the radius <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\varepsilon ^{(k)}$\n</tex-math></inline-formula> within which is looked for nearby training RPs. The number <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$n^{(k)}$\n</tex-math></inline-formula> of RPs is defined by the accuracy that is targeted at level <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$k$\n</tex-math></inline-formula> of the hierarchical positioning algorithm. The distance <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\lambda ^{(k)}$\n</tex-math></inline-formula> determines not only the spatial uniformity of the resulting RPs, but also the complexity of the algorithm: by reducing <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\lambda ^{(k)}$\n</tex-math></inline-formula>, the RPs will be placed more uniformly over the area <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$P$\n</tex-math></inline-formula>, but the complexity of MDA increases as the number of virtual RPs to be searched increases in an inverse proportion to the quadrate of <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\lambda ^{(k)}$\n</tex-math></inline-formula>. Finally, the radius <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\varepsilon ^{(k)}$\n</tex-math></inline-formula> will have an influence on the performance of the HPA. When the radius is small, the resulting database <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB^{(k)}$\n</tex-math></inline-formula> will have a more uniform placement of the RPs, but the probability of finding a nearby training RP decreases, such that the RSS of more RPs need to be determined using the LGP algorithm. On the other hand, when the radius is selected large, the resulting database <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB^{(k)}$\n</tex-math></inline-formula> will be less spatially uniform, but more training RPs will be present in <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB^{(k)}$\n</tex-math></inline-formula>. In the numerical results, we will evaluate the effect of the parameters <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\lambda ^{(k)}$\n</tex-math></inline-formula> and <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\varepsilon ^{(k)}$\n</tex-math></inline-formula> on the performance of the positioning.</p></div><div class=\"section_2\" id=\"sec2c\"><h3>C. The Local Gaussian Process Algorithm</h3><p>The Local Gaussian Process (LGP) algorithm is used to reduce the computational complexity of the Gaussian Process (GP) algorithm, which is used to predict unknown RSS values at positions that are not in the training database. In <a ref-type=\"bibr\" anchor=\"ref12\" id=\"context_ref_12_2c\" data-range=\"ref12\">[12]</a>, various GP sparsification methods are introduced. LGP is proposed from physical point of view, while various GP sparsification methods in <a ref-type=\"bibr\" anchor=\"ref12\" id=\"context_ref_12_2c\" data-range=\"ref12\">[12]</a> are introduced from a mathematical point of view.</p><p class=\"has-inline-formula\">In this section, we first review the GP algorithm. This algorithm starts from the property that RSS values at surrounding positions are correlated. Because of this correlation, it is possible to describe the RSS at positions where the RSS is not known as function of the RSS at positions where the RSS value is measured. The GP algorithm uses the Gaussian kernel to describe this correlation. As a result, the correlation matrix between the noisy RSS values <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$RSS_{i}$\n</tex-math></inline-formula> at positions <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\mathbf {c}_{i} = \\{ x_{i},y_{i}\\}$\n</tex-math></inline-formula>, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$i=1,\\ldots,n$\n</tex-math></inline-formula>, measured during the training phase, can be written as:<disp-formula id=\"deqn2\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} cov{\\rho }= \\mathbf {Q} + \\mathbf {S}\\tag{2}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} cov{\\rho }= \\mathbf {Q} + \\mathbf {S}\\tag{2}\\end{equation*}\n</span></span></disp-formula> where <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">${\\rho (i)} = RSS_{i}$\n</tex-math></inline-formula>, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\mathbf {Q}_{i,j} = k(\\mathbf {c}_{i},\\mathbf {c}_{j})$\n</tex-math></inline-formula>, and <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\mathbf {S} = diag\\{\\sigma _{i}^{2}\\}$\n</tex-math></inline-formula> is the diagonal matrix of the variances of the measured RSS values <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$RSS_{i}$\n</tex-math></inline-formula> <a ref-type=\"bibr\" anchor=\"ref13\" id=\"context_ref_13_2c\" data-range=\"ref13\">[13]</a>. Further, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$k(\\mathbf {c}_{i},\\mathbf {c}_{j})$\n</tex-math></inline-formula> is the Gaussian kernel function:<disp-formula id=\"deqn3\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} k(\\mathbf {c}_{i},\\mathbf {c}_{j})=\\sigma _{f}^{2} \\exp \\left({-\\frac {1}{2l^{2}}|| \\mathbf {c}_{i}-\\mathbf {c}_{j}||^{2}}\\right)\\tag{3}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} k(\\mathbf {c}_{i},\\mathbf {c}_{j})=\\sigma _{f}^{2} \\exp \\left({-\\frac {1}{2l^{2}}|| \\mathbf {c}_{i}-\\mathbf {c}_{j}||^{2}}\\right)\\tag{3}\\end{equation*}\n</span></span></disp-formula> where <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\sigma _{f}^{2}$\n</tex-math></inline-formula> and <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$l$\n</tex-math></inline-formula> are the signal variance and length scale, respectively, determining the correlation with the RSS values at surrounding positions. The parameters <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\sigma ^{2}_{f}$\n</tex-math></inline-formula>, and <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$l$\n</tex-math></inline-formula> can be estimated using hyper-parameter estimation <a ref-type=\"bibr\" anchor=\"ref13\" id=\"context_ref_13_2c\" data-range=\"ref13\">[13]</a>. This covariance matrix can be used to predict the RSS value <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$RSS_{\\ast}$\n</tex-math></inline-formula> at an arbitrary position <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\mathbf {c}_{\\ast} = \\{ x_{\\ast},y_{\\ast}\\}$\n</tex-math></inline-formula>. The posterior distribution of the RSS value at any position is modeled as a Gaussian random variable, i.e. <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$(RSS_{\\ast}|\\mathbf {c}_{\\ast})=\\mathcal {N}(RSS_{\\ast};\\mu _{\\ast},\\sigma ^{2}_{\\ast})$\n</tex-math></inline-formula>, where <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\mu _{\\ast}$\n</tex-math></inline-formula> and <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\sigma ^{2}_{\\ast}$\n</tex-math></inline-formula> are given by:<disp-formula id=\"deqn4-deqn5\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{align*} \\mu _{\\ast}=&amp;\\mathbf {k}_{\\ast}^{T}(\\mathbf {Q}+\\mathbf {S})^{-1}{\\rho }\\tag{4}\\\\ \\sigma ^{2}_{\\ast}=&amp;k(\\mathbf {c}_{\\ast},\\mathbf {c}_{\\ast})-\\mathbf {k}_{\\ast}^{T}(\\mathbf {Q}+\\mathbf {S})^{-1}\\mathbf {k}_{\\ast}+\\sigma ^{2}_{n}\\tag{5}\\end{align*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{align*} \\mu _{\\ast}=&amp;\\mathbf {k}_{\\ast}^{T}(\\mathbf {Q}+\\mathbf {S})^{-1}{\\rho }\\tag{4}\\\\ \\sigma ^{2}_{\\ast}=&amp;k(\\mathbf {c}_{\\ast},\\mathbf {c}_{\\ast})-\\mathbf {k}_{\\ast}^{T}(\\mathbf {Q}+\\mathbf {S})^{-1}\\mathbf {k}_{\\ast}+\\sigma ^{2}_{n}\\tag{5}\\end{align*}\n</span></span></disp-formula> where <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\sigma ^{2}_{n} $\n</tex-math></inline-formula> is the measurement variance, and <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\mathbf {k}_{\\ast}(i) = k(\\mathbf {c}_{\\ast},\\mathbf {c}_{i})$\n</tex-math></inline-formula>, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$i=1,\\ldots,n$\n</tex-math></inline-formula>. The estimate of the RSS value at position <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\mathbf {c}_{\\ast} = \\{ x_{\\ast},y_{\\ast}\\}$\n</tex-math></inline-formula> equals <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$RSS_{\\ast}= \\mu _{\\ast} $\n</tex-math></inline-formula> and the uncertainty on the estimated RSS is <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\sigma ^{2}_{\\ast}$\n</tex-math></inline-formula>.</p><p class=\"has-inline-formula\">For a large area containing several hundreds of RPs, computing the RSS values with <a ref-type=\"disp-formula\" anchor=\"deqn4-deqn5\" href=\"#deqn4-deqn5\" class=\"fulltext-link\">equation (4) and (5)</a> are computationally demanding because of the inversion of the large covariance matrix <a ref-type=\"disp-formula\" anchor=\"deqn2\" href=\"#deqn2\" class=\"fulltext-link\">(2)</a>. However, in an indoor environment, we may assume that RPs at a large distance from the position where we want to estimate the RSS value, are blocked by several walls and other objects. Hence, the covariance <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$k(\\cdot,\\cdot)$\n</tex-math></inline-formula> between the RSS value of those far away RPs and the RSS value at the considered position will be approximately zero. As a result, it is a reasonable assumption that only training RPs close to the considered position will contribute to the RSS value at considered position. The LGP algorithm restricts the training RPs that contribute to the RSS value at position <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\mathbf {c}_{\\ast}$\n</tex-math></inline-formula> to a training set <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$TS_{\\ast}$\n</tex-math></inline-formula>, setting <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$k(x_{\\ast},x_{i})=0$\n</tex-math></inline-formula> if <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$x_{i}\\not \\in TS_{\\ast}$\n</tex-math></inline-formula>. Assuming the number of RPs in <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$TS_{\\ast}$\n</tex-math></inline-formula> equals <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$L$\n</tex-math></inline-formula>, the LGP algorithm simplifies <a ref-type=\"disp-formula\" anchor=\"deqn4-deqn5\" href=\"#deqn4-deqn5\" class=\"fulltext-link\">equation (4) and (5)</a> by only considering the <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$k$\n</tex-math></inline-formula> nearest RPs. i.e. <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\mathbf {k}_{\\ast}$\n</tex-math></inline-formula> and <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">${\\rho }$\n</tex-math></inline-formula> reduce to a <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$L \\times 1$\n</tex-math></inline-formula> vector, and <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$cov{\\rho }$\n</tex-math></inline-formula> <a ref-type=\"disp-formula\" anchor=\"deqn2\" href=\"#deqn2\" class=\"fulltext-link\">(2)</a> to a <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$L \\times L$\n</tex-math></inline-formula> matrix. Compared to the complexity <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\mathcal {O}(n^{3})$\n</tex-math></inline-formula> when all <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$n$\n</tex-math></inline-formula> RPs in the training database are used, the LGP algorithm has complexity <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\mathcal {O}(nL)$\n</tex-math></inline-formula> to select the <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$L$\n</tex-math></inline-formula> nearest RPs and <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\mathcal {O}(L^{3})$\n</tex-math></inline-formula> to invert the reduced-size covariance matrix <a ref-type=\"disp-formula\" anchor=\"deqn2\" href=\"#deqn2\" class=\"fulltext-link\">(2)</a>.</p><p class=\"has-inline-formula\">To illustrate the LGP algorithm, we consider the RSS radio map of a WiFi access point in an indoor environment. The true radio map is created using the WinProp tool from AWE Communications <a ref-type=\"bibr\" anchor=\"ref23\" id=\"context_ref_23_2c\" data-range=\"ref23\">[23]</a>. The area is a <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$19.5m \\times 48.5m$\n</tex-math></inline-formula> rectangle, containing 18 rooms in the same floor. <a ref-type=\"fig\" anchor=\"fig4\" class=\"fulltext-link\">Figure 4</a> shows the true radio maps, including all <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$n=3318$\n</tex-math></inline-formula> RPs.\n<div class=\"figure figure-full\" id=\"fig4\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang4-2939545-large.gif\" data-fig-id=\"fig4\"><img src=\"\" data-src-img=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang4-2939545-small.gif\" alt=\"FIGURE 4. - True radio map created by WinProp.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 4. </b><fig><p>True radio map created by WinProp.</p></fig></div><p class=\"links\"><a href=\"/document/8825770/figures\" class=\"all\">Show All</a></p></div></p><p class=\"has-inline-formula\"><a ref-type=\"fig\" anchor=\"fig5\" class=\"fulltext-link\">Figure 5</a> shows the radio maps created by GP, LGP and LDPL, respectively. In this simulation, we randomly select 80 nodes from the database as training data. And use different algorithms to estimate the other nodes\u2019 RSS values. The parameters of the GP are estimated based on the training data, considering all <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$n=80$\n</tex-math></inline-formula> RPs. In LGP algorithm, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$L$\n</tex-math></inline-formula> is set to 4. And the Log-Distance Path Model (LDPL) <a ref-type=\"bibr\" anchor=\"ref24\" id=\"context_ref_24_2c\" data-range=\"ref24\">[24]</a>, where the parameters of the LDPL model are estimated based on the training data. The uncertainty of RP <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$i$\n</tex-math></inline-formula> is defined as follows:<disp-formula id=\"deqn6\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} Diff_{i} = (RSS_{i}-\\widehat {RSS}_{i})^{2}\\tag{6}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} Diff_{i} = (RSS_{i}-\\widehat {RSS}_{i})^{2}\\tag{6}\\end{equation*}\n</span></span></disp-formula> where <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\widehat {RSS}_{i,j}$\n</tex-math></inline-formula> and <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$RSS_{i,j}$\n</tex-math></inline-formula> are estimated and true RSS values at RP <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$j$\n</tex-math></inline-formula>, respectively.\n<div class=\"figure figure-full\" id=\"fig5\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang5abcdef-2939545-large.gif\" data-fig-id=\"fig5\"><img src=\"\" data-src-img=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang5abcdef-2939545-small.gif\" alt=\"FIGURE 5. - The uncertainty on the RSS value(a) radio map using LGP (b) LGP RSS uncertainty (c) radio map using GP, &#10;$K=4$&#10; (d) GP RSS uncertainty (e) radio map using LDPL. (b) LDPL RSS uncertainty.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 5. </b><fig><p class=\"has-inline-formula\">The uncertainty on the RSS value(a) radio map using LGP (b) LGP RSS uncertainty (c) radio map using GP, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$K=4$\n</tex-math></inline-formula> (d) GP RSS uncertainty (e) radio map using LDPL. (b) LDPL RSS uncertainty.</p></fig></div><p class=\"links\"><a href=\"/document/8825770/figures\" class=\"all\">Show All</a></p></div></p><p>As can be observed, the radio maps for GP and LGP are similar to the true radio map. The LDPL model, which is known to fail at positions far from the signal source, resembles less the true radio map.</p><p>We also compute the average uncertainty over all positions. The average uncertainty is defined as:<disp-formula id=\"deqn7\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} Diff = \\frac {\\sum _{i=1}^{m}{Diff_{i}}}{m}\\tag{7}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} Diff = \\frac {\\sum _{i=1}^{m}{Diff_{i}}}{m}\\tag{7}\\end{equation*}\n</span></span></disp-formula></p><p>GP has the lowest average uncertainty, which is about 8.00, followed by LGP with an average of 9.42. The highest average comes from LDPL, which is 34.86.</p><p class=\"has-inline-formula\">For more accurate result, we use <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\hat {\\sigma }_{r}$\n</tex-math></inline-formula>, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$RMSE_{r}$\n</tex-math></inline-formula> and <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$time$\n</tex-math></inline-formula> to evaluate these three algorithms, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\hat {\\sigma }_{r}$\n</tex-math></inline-formula> and <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$RMSE_{r}$\n</tex-math></inline-formula> are defined as:<disp-formula id=\"deqn8-deqn9\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{align*} \\hat {\\sigma }^{2}_{r}=&amp;\\sum _{i}\\sigma _{i}^{2}/m\\tag{8}\\\\ RMSE_{r}=&amp;\\sqrt {\\frac {\\sum _{i}{Diff_{i}}}{m}}\\tag{9}\\end{align*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{align*} \\hat {\\sigma }^{2}_{r}=&amp;\\sum _{i}\\sigma _{i}^{2}/m\\tag{8}\\\\ RMSE_{r}=&amp;\\sqrt {\\frac {\\sum _{i}{Diff_{i}}}{m}}\\tag{9}\\end{align*}\n</span></span></disp-formula> where <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$m$\n</tex-math></inline-formula> is the number of virtual RPs.</p><p class=\"has-inline-formula\"><inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$time$\n</tex-math></inline-formula> refers to the time for calculating all the RPs\u2019 RSS values in the database.</p><p class=\"has-inline-formula\">And we also define a parameter <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\rho _{\\ast}$\n</tex-math></inline-formula> to indicate the density of the database:<disp-formula id=\"deqn10\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} \\rho _{\\ast} = n_{\\ast}/S\\tag{10}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} \\rho _{\\ast} = n_{\\ast}/S\\tag{10}\\end{equation*}\n</span></span></disp-formula> where <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$n_{\\ast}$\n</tex-math></inline-formula> is the number of RPs in the database. <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\rho _{tr}$\n</tex-math></inline-formula> and <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\rho _{v}$\n</tex-math></inline-formula> refers the density of the training database and virtual database, respectively.</p><p class=\"has-inline-formula\">In the following simulation, we set <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\rho _{tr}$\n</tex-math></inline-formula> varies from 0.02 to 1, the training RPs are selected randomly. For each <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\rho _{tr}$\n</tex-math></inline-formula>, we simulate 2000 times with <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\rho _{v}=1$\n</tex-math></inline-formula>, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\sigma ^{2}_{n} =0$\n</tex-math></inline-formula> and <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$L=4$\n</tex-math></inline-formula>. <a ref-type=\"fig\" anchor=\"fig6\" class=\"fulltext-link\">Fig.6</a> is the result.\n<div class=\"figure figure-full\" id=\"fig6\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang6-2939545-large.gif\" data-fig-id=\"fig6\"><img src=\"\" data-src-img=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang6-2939545-small.gif\" alt=\"FIGURE 6. - The &#10;$\\hat {\\sigma }_{r}$&#10; of GP and LGP.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 6. </b><fig><p class=\"has-inline-formula\">The <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\hat {\\sigma }_{r}$\n</tex-math></inline-formula> of GP and LGP.</p></fig></div><p class=\"links\"><a href=\"/document/8825770/figures\" class=\"all\">Show All</a></p></div></p><p class=\"has-inline-formula\">In <a ref-type=\"fig\" anchor=\"fig6\" class=\"fulltext-link\">Fig.6</a>, We can see that GP has a smaller <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\hat {\\sigma }_{r}$\n</tex-math></inline-formula> than LGP, but the differences between them is slightly small. We compare GP, LGP and LDPL in RMSE and the time complexity in <a ref-type=\"fig\" anchor=\"fig7\" class=\"fulltext-link\">Fig.7</a>.\n<div class=\"figure figure-full\" id=\"fig7\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang7ab-2939545-large.gif\" data-fig-id=\"fig7\"><img src=\"\" data-src-img=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang7ab-2939545-small.gif\" alt=\"FIGURE 7. - &#10;$RMSE_{r}$&#10; and Time complexity vary with different &#10;$\\rho _{tr}$&#10;. (a) is &#10;$RMSE_{r}$&#10; and (b) is the time spend in creating the virtual database using different algorithms.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 7. </b><fig><p class=\"has-inline-formula\"><inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$RMSE_{r}$\n</tex-math></inline-formula> and Time complexity vary with different <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\rho _{tr}$\n</tex-math></inline-formula>. (a) is <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$RMSE_{r}$\n</tex-math></inline-formula> and (b) is the time spend in creating the virtual database using different algorithms.</p></fig></div><p class=\"links\"><a href=\"/document/8825770/figures\" class=\"all\">Show All</a></p></div></p><p>In <a ref-type=\"fig\" anchor=\"fig7\" class=\"fulltext-link\">Fig.7(a)</a>, GP performs the best, followed by LGP, and LDPL performs the worst. But the differences between GP and LGP is small. In <a ref-type=\"fig\" anchor=\"fig7\" class=\"fulltext-link\">Fig.7(b)</a>, LDPL has the lowest time complexity, followed by LGP, and GP. In summary, LGP keeps a good balance between RMSE and time complexity.</p></div><div class=\"section_2\" id=\"sec2d\"><h3>D. The Weighted <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$K$\n</tex-math></inline-formula> Nearest Neighbors Algorithm</h3><p class=\"has-inline-formula\">Using the two previous algorithms, we are able to generate the hierarchical database required for our HPA positioning algorithm. With this hierarchical database, we will successively estimate the position at the different levels, starting at the highest level. At each level, we use the weighted <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$K$\n</tex-math></inline-formula> nearest neighbors (WKNN) algorithm, which searches in the database for the <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$K$\n</tex-math></inline-formula> RPs with RSS values closest to the user, and takes a weighted sum of the positions of these nearest RPs to estimate the position. However, as the uncertainty on the RSS value of some RPs in the database can be high, the accuracy of the standard WKNN algorithm can be low. In order to improve the accuracy, we change the algorithm to take into account the uncertainty on the RSS values in the database.</p><p class=\"has-inline-formula\">Let us assume we measure the RSS values <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$N$\n</tex-math></inline-formula> times. Assume the user measures the RSS values <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\{RSS_{\\ell,t}|\\ell =1,\\ldots,a\\}$\n</tex-math></inline-formula> during the <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$t^{th}$\n</tex-math></inline-formula> measurement, where <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$a$\n</tex-math></inline-formula> is the number of signal sources. The signal distance to RP <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$j$\n</tex-math></inline-formula> in the database at level <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$k$\n</tex-math></inline-formula> is defined as <disp-formula id=\"deqn11\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} d_{j,t}=\\sum _{\\ell =1}^{a} \\delta ^{(k)}_{j,\\ell }|RSS_{\\ell,t} - RSS^{(k)}_{j,\\ell }|\\tag{11}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} d_{j,t}=\\sum _{\\ell =1}^{a} \\delta ^{(k)}_{j,\\ell }|RSS_{\\ell,t} - RSS^{(k)}_{j,\\ell }|\\tag{11}\\end{equation*}\n</span></span></disp-formula> where <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$RSS^{(k)}_{j,\\ell }$\n</tex-math></inline-formula> is the RSS value at RP <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$j$\n</tex-math></inline-formula> for signal source <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\ell $\n</tex-math></inline-formula>, and <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\delta ^{(k)}_{j,\\ell }$\n</tex-math></inline-formula> is the uncertainty on that RSS value. This distance measure favors more reliable RPs having a small <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\delta ^{(k)}_{j,\\ell }, \\ell =1,\\ldots,a$\n</tex-math></inline-formula> and will disfavor unreliable RPs with high uncertainty <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\delta ^{(k)}_{j,\\ell }$\n</tex-math></inline-formula>. Taking into account that in general the uncertainty of a training RP will be lower than that of a virtual RP, the training data is more likely to be selected with this altered algorithm, improving the accuracy.</p><p class=\"has-inline-formula\">After the selection of the nearest neighbors, the WKNN algorithm estimates the coordinates of the user by weighting the coordinates of the <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$K$\n</tex-math></inline-formula> selected RPs:<disp-formula id=\"deqn12\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} (\\hat {x}_{t}, \\hat {y}_{t})=\\left({\\sum _{j=0}^{K}{\\tilde {w}_{j,t}x^{(k)}_{j}}, \\sum _{j=1}^{K}{\\tilde {w}_{j,t}y^{(k)}_{j}}}\\right)\\tag{12}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} (\\hat {x}_{t}, \\hat {y}_{t})=\\left({\\sum _{j=0}^{K}{\\tilde {w}_{j,t}x^{(k)}_{j}}, \\sum _{j=1}^{K}{\\tilde {w}_{j,t}y^{(k)}_{j}}}\\right)\\tag{12}\\end{equation*}\n</span></span></disp-formula> where <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$(x^{(k)}_{j},y^{(k)}_{j})$\n</tex-math></inline-formula> are the coordinates of RP <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$j$\n</tex-math></inline-formula>, and <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\tilde {w}_{j,t}$\n</tex-math></inline-formula> is the normalized weight:<disp-formula id=\"deqn13\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} \\tilde {w}_{j,t}=\\frac {1/d_{j,t}^{p}}{\\sum _{i=0}^{K}{1/d_{i,t}^{p}}}.\\tag{13}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} \\tilde {w}_{j,t}=\\frac {1/d_{j,t}^{p}}{\\sum _{i=0}^{K}{1/d_{i,t}^{p}}}.\\tag{13}\\end{equation*}\n</span></span></disp-formula></p><p class=\"has-inline-formula\">The variance <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\sigma $\n</tex-math></inline-formula> is defined as follows:<disp-formula id=\"deqn14\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} \\sigma = \\sum _{t=1}^{N}\\frac {\\sum _{i=1}^{K}{\\tilde {w}_{i}[(x_{i}^{(k)}-\\hat {x}_{t})^{2} + (y_{i}^{(k)}-\\hat {y}_{t})^{2}]}}{1-\\sum _{i=1}^{K}{\\tilde {w}_{i}^{2}}}\\tag{14}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} \\sigma = \\sum _{t=1}^{N}\\frac {\\sum _{i=1}^{K}{\\tilde {w}_{i}[(x_{i}^{(k)}-\\hat {x}_{t})^{2} + (y_{i}^{(k)}-\\hat {y}_{t})^{2}]}}{1-\\sum _{i=1}^{K}{\\tilde {w}_{i}^{2}}}\\tag{14}\\end{equation*}\n</span></span></disp-formula></p><p class=\"has-inline-formula\">If we want more accurate result, we can continue our estimation using lower level sub-database <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB^{(k+1)}$\n</tex-math></inline-formula>, which contains more RPs. For reducing the time for searching in database to find the most likely match RPs. We can use the previous result to reduce the searching space.</p><p class=\"has-inline-formula\">In the previous estimation, we calculate the location based on <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$K$\n</tex-math></inline-formula> nearest RPs in <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB^{(k+1)}$\n</tex-math></inline-formula>. We put these <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$K$\n</tex-math></inline-formula> RPs in set <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$TS^{(k)}$\n</tex-math></inline-formula>. Based on <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$TS^{(k)}$\n</tex-math></inline-formula>, we can estimate the user\u2019s most possible located area denoted by <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$S^{(k)}_{t}$\n</tex-math></inline-formula>:<disp-formula id=\"deqn15\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{align*} S^{(k)}_{t}=&amp;\\{(x,y)|x\\subset [min\\{x^{(k)}_{j}\\},max\\{x^{(k)}_{j}\\}], \\\\ y\\subset&amp;[min\\{y^{(k)}_{j}\\}, max\\{y^{(k)}_{j}\\}]\\}, (x^{(k)}_{j},y^{(k)}_{j})\\subset TS^{(k)}\\tag{15}\\end{align*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{align*} S^{(k)}_{t}=&amp;\\{(x,y)|x\\subset [min\\{x^{(k)}_{j}\\},max\\{x^{(k)}_{j}\\}], \\\\ y\\subset&amp;[min\\{y^{(k)}_{j}\\}, max\\{y^{(k)}_{j}\\}]\\}, (x^{(k)}_{j},y^{(k)}_{j})\\subset TS^{(k)}\\tag{15}\\end{align*}\n</span></span></disp-formula></p><p class=\"has-inline-formula\"><a ref-type=\"fig\" anchor=\"fig8\" class=\"fulltext-link\">Fig. 8</a> shows how the area <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$S^{(k)}_{t}$\n</tex-math></inline-formula> is created, where <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$K$\n</tex-math></inline-formula> is set to 3:\n<div class=\"figure figure-full\" id=\"fig8\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang8-2939545-large.gif\" data-fig-id=\"fig8\"><img src=\"\" data-src-img=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang8-2939545-small.gif\" alt=\"FIGURE 8. - Creating &#10;$S$&#10; based on &#10;$TS$&#10;.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 8. </b><fig><p class=\"has-inline-formula\">Creating <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$S$\n</tex-math></inline-formula> based on <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$TS$\n</tex-math></inline-formula>.</p></fig></div><p class=\"links\"><a href=\"/document/8825770/figures\" class=\"all\">Show All</a></p></div></p><p class=\"has-inline-formula\">The area <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$S_{t}$\n</tex-math></inline-formula> is the user\u2019s most likely located place. We select all the node in <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$S^{(k)}_{t}$\n</tex-math></inline-formula> from <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB^{(k+1)}$\n</tex-math></inline-formula> for fine estimation using the algorithm illustrated in this section.</p></div></div>\n<div class=\"section\" id=\"sec3\"><div class=\"header article-hdr\"><div class=\"kicker\">\n                                SECTION III.</div><h2>Numerical Results</h2></div><p>In this experiments, we apply the WiFi fingerprint to test our algorithm. We first compare our proposed virtual database creation algorithm LGP with GP and the widely used Log-Distance Path Loss model. We also evaluate our positioning algorithm with both high and low density training database.</p><div class=\"section_2\" id=\"sec3a\"><h3>A. Set-Up of Indoor Experiment</h3><p class=\"has-inline-formula\">Our test environment consists of 18 room in one floor, with the area of <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$800m^{2}$\n</tex-math></inline-formula>. And 8 APs are placed in this area. The floor plan of the corridor and the position of the APs are shown in <a ref-type=\"fig\" anchor=\"fig9\" class=\"fulltext-link\">Fig. 9</a>.\n<div class=\"figure figure-full\" id=\"fig9\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang9-2939545-large.gif\" data-fig-id=\"fig9\"><img src=\"\" data-src-img=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang9-2939545-small.gif\" alt=\"FIGURE 9. - Floor plan of the office corridor and the position of the APs.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 9. </b><fig><p>Floor plan of the office corridor and the position of the APs.</p></fig></div><p class=\"links\"><a href=\"/document/8825770/figures\" class=\"all\">Show All</a></p></div></p><p class=\"has-inline-formula\">We build a WiFi fingerprint radio map for our environment by means of 3D ray tracing. We use WinProp from AWE communications to create the signal fingerprint database. The database contains 3318 RPs, denoted as <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB$\n</tex-math></inline-formula>. We consider the radio map as the ground truth. In the following simulation, we only use 800 random distributed RPs for training. The others are used for testing.</p><p class=\"has-inline-formula\">For evaluating different algorithms, we define <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$tc$\n</tex-math></inline-formula> and <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$RMSE$\n</tex-math></inline-formula>. <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$RMSE$\n</tex-math></inline-formula> is defined as:<disp-formula id=\"deqn16\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} RMSE=\\sqrt {\\frac {\\sum _{i=1}^{N}{ [(x_{t}-\\hat {x}_{t})^{2}+(y_{t}-\\hat {y}_{t})^{2}]}}{N}}\\tag{16}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} RMSE=\\sqrt {\\frac {\\sum _{i=1}^{N}{ [(x_{t}-\\hat {x}_{t})^{2}+(y_{t}-\\hat {y}_{t})^{2}]}}{N}}\\tag{16}\\end{equation*}\n</span></span></disp-formula> where <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$(x_{t},y_{t}),(\\hat {x}_{t},\\hat {x}_{t})$\n</tex-math></inline-formula> are the true and estimated coordinates, respectively. <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$N$\n</tex-math></inline-formula> is the number of positioning instance.</p><p class=\"has-inline-formula\"><inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$tc$\n</tex-math></inline-formula> refers to the mean time for locating one single RP.</p></div><div class=\"section_2\" id=\"sec3b\"><h3>B. Evaluating the Parameters</h3><p class=\"has-inline-formula\">There are some parameters in HPA, including <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\lambda ^{(k)}$\n</tex-math></inline-formula> in MDA, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$K$\n</tex-math></inline-formula> in WKNN, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\varepsilon ^{(k)}$\n</tex-math></inline-formula> and <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$L$\n</tex-math></inline-formula> in LGP. All of these parameters determines the complexity and positioning accuracy of HPA. We first evaluate these parameters to get the optimized values.</p><div class=\"section_2\" id=\"sec3b1\"><h4>1) <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\lambda ^{(k)}$\n</tex-math></inline-formula></h4><p class=\"has-inline-formula\"><inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\lambda ^{(k)}$\n</tex-math></inline-formula> determines the density of <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB_{v}^{(k)}$\n</tex-math></inline-formula>. Different <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB_{v}^{(k)}$\n</tex-math></inline-formula> result in different <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB^{(k)}$\n</tex-math></inline-formula>, as a result, the positioning accuracy might be affected.</p><p class=\"has-inline-formula\">In this simulation, we test different <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\lambda ^{(k)}$\n</tex-math></inline-formula>. We apply the LGP for estimating the virtual RPs\u2019 RSS values. The stardand WKNN algorithm is applied for positioning. The other parameters are set as follows: <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\varepsilon =0$\n</tex-math></inline-formula>, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$K=4$\n</tex-math></inline-formula>, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$L=4$\n</tex-math></inline-formula>,<inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$n^{k}=80$\n</tex-math></inline-formula>; <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\sigma ^{2}_{f}$\n</tex-math></inline-formula>, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\sigma ^{2}_{n}$\n</tex-math></inline-formula> and <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$l$\n</tex-math></inline-formula> are estimated using hyper-parameter estimation. We build different <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB^{(k)}$\n</tex-math></inline-formula> based on different <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB_{v}^{(k)}$\n</tex-math></inline-formula> for positioning. Results comes from 20000 positioning instance.</p><p class=\"has-inline-formula\"><a ref-type=\"fig\" anchor=\"fig10\" class=\"fulltext-link\">Fig. 10</a> is the positioning result from different <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\lambda ^{(k)}$\n</tex-math></inline-formula>:\n<div class=\"figure figure-full\" id=\"fig10\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang10ab-2939545-large.gif\" data-fig-id=\"fig10\"><img src=\"\" data-src-img=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang10ab-2939545-small.gif\" alt=\"FIGURE 10. - CDF and Mean error vary with different &#10;$\\lambda ^{(k)}$&#10;. The training curve means using the training database for positioning, and random means using 80 randomly selected RPs for positioning.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 10. </b><fig><p class=\"has-inline-formula\">CDF and Mean error vary with different <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\lambda ^{(k)}$\n</tex-math></inline-formula>. The training curve means using the training database for positioning, and random means using 80 randomly selected RPs for positioning.</p></fig></div><p class=\"links\"><a href=\"/document/8825770/figures\" class=\"all\">Show All</a></p></div></p><p class=\"has-inline-formula\">In this simulation, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\lambda ^{(k)}$\n</tex-math></inline-formula> is set to 0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, 2, 2.25, 2.5, 2.75, 3, and 3.25, respectively. We also use the training database, containing 800 training RPs, and randomly selected 80 RPs for positioning. <a ref-type=\"fig\" anchor=\"fig10\" class=\"fulltext-link\">Fig.10(a)</a> only contains the result when <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\lambda ^{(k)}$\n</tex-math></inline-formula> is set to 0.25, 1.25, 2.25, and 3.25. In <a ref-type=\"fig\" anchor=\"fig10\" class=\"fulltext-link\">Fig.10</a>, positioning using the training database performs the best, while the random database worst. The difference between variant <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\lambda ^{(k)}$\n</tex-math></inline-formula> is slightly small. In <a ref-type=\"fig\" anchor=\"fig10\" class=\"fulltext-link\">Fig.10(b)</a>, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\lambda ^{(k)}$\n</tex-math></inline-formula> has almost no effect on the performance. But building the database with different <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\lambda ^{(k)}$\n</tex-math></inline-formula> cost different time. <a ref-type=\"fig\" anchor=\"fig11\" class=\"fulltext-link\">Fig.11</a> gives the time for constructing the virtual database with different <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\lambda ^{(k)}$\n</tex-math></inline-formula>:\n<div class=\"figure figure-full\" id=\"fig11\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang11-2939545-large.gif\" data-fig-id=\"fig11\"><img src=\"\" data-src-img=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang11-2939545-small.gif\" alt=\"FIGURE 11. - Time for building the virtual database.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 11. </b><fig><p>Time for building the virtual database.</p></fig></div><p class=\"links\"><a href=\"/document/8825770/figures\" class=\"all\">Show All</a></p></div></p><p class=\"has-inline-formula\"><a ref-type=\"fig\" anchor=\"fig11\" class=\"fulltext-link\">Fig.11</a> shows that the time decrease when <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\lambda ^{(k)}$\n</tex-math></inline-formula> increase. The result from <a ref-type=\"fig\" anchor=\"fig10\" class=\"fulltext-link\">Fig.10</a> and <a ref-type=\"fig\" anchor=\"fig11\" class=\"fulltext-link\">Fig.11</a> tell us that we can use as large <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\lambda ^{(k)}$\n</tex-math></inline-formula> as possible to reduce the time for constructing the database.</p></div><div class=\"section_2\" id=\"sec3b2\"><h4>2) <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\varepsilon ^{(k)}$\n</tex-math></inline-formula></h4><p class=\"has-inline-formula\"><inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\varepsilon ^{(k)}$\n</tex-math></inline-formula> determines the distance that we can use the training data directly. A big <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\varepsilon ^{(k)}$\n</tex-math></inline-formula> might break the distribution of the RPs, but will introduce more reliable RSS values. In this section, we will evaluate the performance with different <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\varepsilon ^{(k)}$\n</tex-math></inline-formula>.</p><p class=\"has-inline-formula\">Similar with the previous setting, we apply the LGP for estimating the virtual RPs\u2019 RSS values, and the traditional WKNN algorithm for positioning. The other parameters are set as follows: <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\lambda ^{(k)}=1.25$\n</tex-math></inline-formula>, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$K=4$\n</tex-math></inline-formula>, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$L=4$\n</tex-math></inline-formula>,<inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$n^{k}=80$\n</tex-math></inline-formula>; <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\sigma ^{2}_{f}$\n</tex-math></inline-formula>, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\sigma ^{2}_{n}$\n</tex-math></inline-formula> and <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$l$\n</tex-math></inline-formula> are estimated using hyper-parameter estimation. We build <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB^{(k)}$\n</tex-math></inline-formula> with different <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\varepsilon ^{(k)}$\n</tex-math></inline-formula> based on <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB_{v}^{(k)}$\n</tex-math></inline-formula> for positioning.</p><p class=\"has-inline-formula\">We first look at the percentage of training data in <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB^{(k)}$\n</tex-math></inline-formula>. A large <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\varepsilon ^{(k)}$\n</tex-math></inline-formula> result in more training data be used. <a ref-type=\"fig\" anchor=\"fig12\" class=\"fulltext-link\">Fig.12</a> shows the result. Results comes from 20000 positioning instance.\n<div class=\"figure figure-full\" id=\"fig12\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang12-2939545-large.gif\" data-fig-id=\"fig12\"><img src=\"\" data-src-img=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang12-2939545-small.gif\" alt=\"FIGURE 12. - percentage of training data in &#10;$DB^{(k)}$&#10; varies with &#10;$\\varepsilon ^{(k)}$&#10;.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 12. </b><fig><p class=\"has-inline-formula\">percentage of training data in <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB^{(k)}$\n</tex-math></inline-formula> varies with <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\varepsilon ^{(k)}$\n</tex-math></inline-formula>.</p></fig></div><p class=\"links\"><a href=\"/document/8825770/figures\" class=\"all\">Show All</a></p></div></p><p class=\"has-inline-formula\">The result in <a ref-type=\"fig\" anchor=\"fig12\" class=\"fulltext-link\">Fig.12</a> shows what we expected. The percentage increase as the grows of <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\varepsilon ^{(k)}$\n</tex-math></inline-formula>.</p><p class=\"has-inline-formula\">More training data introduces more reliable data, but the breaks the distribution of the RPs in <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB^{(k)}$\n</tex-math></inline-formula>. We explore the positioning performance with different <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\varepsilon ^{(k)}$\n</tex-math></inline-formula>. <a ref-type=\"fig\" anchor=\"fig13\" class=\"fulltext-link\">Fig.13</a> gives the result.\n<div class=\"figure figure-full\" id=\"fig13\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang13ab-2939545-large.gif\" data-fig-id=\"fig13\"><img src=\"\" data-src-img=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang13ab-2939545-small.gif\" alt=\"FIGURE 13. - CDF and Mean error vary with different &#10;$\\varepsilon ^{(k)}$&#10;. The training curve means using the training database for positioning, and random means using 80 randomly selected RPs for positioning.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 13. </b><fig><p class=\"has-inline-formula\">CDF and Mean error vary with different <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\varepsilon ^{(k)}$\n</tex-math></inline-formula>. The training curve means using the training database for positioning, and random means using 80 randomly selected RPs for positioning.</p></fig></div><p class=\"links\"><a href=\"/document/8825770/figures\" class=\"all\">Show All</a></p></div></p><p class=\"has-inline-formula\">In this simulation, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\varepsilon ^{(k)}$\n</tex-math></inline-formula> is set to 0, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, and 1, respectively. We also use the training database, containing 800 training RPs, and a randomly selected 80 RPs for positioning. <a ref-type=\"fig\" anchor=\"fig13\" class=\"fulltext-link\">Fig.13(a)</a> only contains the result when <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\varepsilon ^{(k)}$\n</tex-math></inline-formula> is set to 0, 0.25, 0.5, 0.75, and 1. In <a ref-type=\"fig\" anchor=\"fig13\" class=\"fulltext-link\">Fig.13</a>, positioning using the training database performs the best, different <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\varepsilon ^{(k)}$\n</tex-math></inline-formula> doesn\u2019t result in significant difference in performance. When <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\varepsilon ^{(k)}=1$\n</tex-math></inline-formula>, which means all the RPs are training nodes, the performance is not the best. When <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\varepsilon ^{(k)}=0$\n</tex-math></inline-formula>, which means the least training RPs are included, the performance is not the worst. <a ref-type=\"fig\" anchor=\"fig13\" class=\"fulltext-link\">Fig.13(b)</a> shows that the best result is achieved when the <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\varepsilon ^{(k)}$\n</tex-math></inline-formula> is set to a middle value.</p></div><div class=\"section_2\" id=\"sec3b3\"><h4>3) <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$L$\n</tex-math></inline-formula></h4><p class=\"has-inline-formula\"><inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$L$\n</tex-math></inline-formula> is the number of training RPs used for estimating the RSS values for a given virtual nodes in LGP. A large <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$L$\n</tex-math></inline-formula> introduces more training data, and more accurate result obtained. But the time for estimating the RSS values will be increased. In this section, we explore to find a good balance between the accuracy and time for building the virtual database.</p><p class=\"has-inline-formula\">Similar with the previous setting, we apply the LGP for estimating the virtual RPs\u2019 RSS values, and the traditional WKNN algorithm for positioning. The other parameters are set as follows: <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\lambda ^{(k)}=1.25$\n</tex-math></inline-formula>, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$K=4$\n</tex-math></inline-formula>, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$n^{k}=80$\n</tex-math></inline-formula>, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\varepsilon ^{(k)}=0.5$\n</tex-math></inline-formula>; <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\sigma ^{2}_{f}$\n</tex-math></inline-formula>, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\sigma ^{2}_{n}$\n</tex-math></inline-formula> and <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$l$\n</tex-math></inline-formula> are estimated using hyper-parameter estimation. We build <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB^{(k)}$\n</tex-math></inline-formula> based on <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB_{v}^{(k)}$\n</tex-math></inline-formula> with different <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$L$\n</tex-math></inline-formula> for positioning. Results comes from 20000 positioning instance.</p><p class=\"has-inline-formula\"><a ref-type=\"fig\" anchor=\"fig14\" class=\"fulltext-link\">Fig.14</a> shows the result.\n<div class=\"figure figure-full\" id=\"fig14\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang14ab-2939545-large.gif\" data-fig-id=\"fig14\"><img src=\"\" data-src-img=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang14ab-2939545-small.gif\" alt=\"FIGURE 14. - CDF and Mean error vary with different &#10;$L$&#10;. The training curve means using the training database for positioning, and random means using 80 randomly selected RPs for positioning.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 14. </b><fig><p class=\"has-inline-formula\">CDF and Mean error vary with different <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$L$\n</tex-math></inline-formula>. The training curve means using the training database for positioning, and random means using 80 randomly selected RPs for positioning.</p></fig></div><p class=\"links\"><a href=\"/document/8825770/figures\" class=\"all\">Show All</a></p></div></p><p class=\"has-inline-formula\">In this simulation, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$L$\n</tex-math></inline-formula> is set from 2 to 15. Positioning using training database and randomly selected database are included. In <a ref-type=\"fig\" anchor=\"fig14\" class=\"fulltext-link\">Fig. 14(a)</a>, we can see that different <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$L's$\n</tex-math></inline-formula> CDF curve looks similar to each other. When <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$L=2$\n</tex-math></inline-formula>, we find that the positioning accuracy is not as good as others. <a ref-type=\"fig\" anchor=\"fig14\" class=\"fulltext-link\">Fig.14(b)</a> proves our observation. The reason is that using a small <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$L$\n</tex-math></inline-formula> means fewer training data used for estimating the virtual RP\u2019s RSS values. As a result, the positioning result is not as good as using more training data. But a large <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$L$\n</tex-math></inline-formula> does not leads to better performance. This result proves assumption 1. We needn\u2019t to using all the training data for estimation.</p></div><div class=\"section_2\" id=\"sec3b4\"><h4>4) <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$K$\n</tex-math></inline-formula></h4><p class=\"has-inline-formula\"><inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$K$\n</tex-math></inline-formula> is the number of nodes used for positioning. In this simulation, we want to find the best <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$K$\n</tex-math></inline-formula> for estimation. We apply the traditional WKNN algorithm for positioning based on the training database. We set <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$K$\n</tex-math></inline-formula> increase from 1 to 10. Results comes from 20000 positioning instance.</p><p class=\"has-inline-formula\"><a ref-type=\"fig\" anchor=\"fig15\" class=\"fulltext-link\">Fig.15</a> shows the result.\n<div class=\"figure figure-full\" id=\"fig15\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang15ab-2939545-large.gif\" data-fig-id=\"fig15\"><img src=\"\" data-src-img=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang15ab-2939545-small.gif\" alt=\"FIGURE 15. - CDF and Mean error vary with different &#10;$K$&#10;.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 15. </b><fig><p class=\"has-inline-formula\">CDF and Mean error vary with different <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$K$\n</tex-math></inline-formula>.</p></fig></div><p class=\"links\"><a href=\"/document/8825770/figures\" class=\"all\">Show All</a></p></div></p><p class=\"has-inline-formula\">The result from <a ref-type=\"fig\" anchor=\"fig15\" class=\"fulltext-link\">Fig.15(a)</a> shows that a smaller or larger <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$K$\n</tex-math></inline-formula> is not good choice. <a ref-type=\"fig\" anchor=\"fig15\" class=\"fulltext-link\">Fig.15(b)</a> tells us that using 3 nodes for positioning performs the best.</p></div></div><div class=\"section_2\" id=\"sec3c\"><h3>C. Evaluating the Improved WKNN Algorithm</h3><p class=\"has-inline-formula\">The difference between standard WKNN and improved WKNN algorithm is the distance definition. In this simulation, we want to evaluate the improved WKNN algorithm both in sparse and dense database. We create two virtual databases using MDA and LGP based on 40 randomly selected RPs. One is sparse virtual database, containing 40 virtual points denoted as <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB^{(1) }$\n</tex-math></inline-formula>, while the other one contains 400 virtual points, denoted as <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB^{(2) }$\n</tex-math></inline-formula>. In MDA algorithm, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\lambda ^{(1) }=\\lambda ^{(2) }=1.25$\n</tex-math></inline-formula>. In LGP algorithm, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$L=5$\n</tex-math></inline-formula>, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\varepsilon ^{(1) }=\\varepsilon ^{(2) }=0.5$\n</tex-math></inline-formula>. In standard and improved WKNN algorithm, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$K=3$\n</tex-math></inline-formula>.</p><p><a ref-type=\"fig\" anchor=\"fig16\" class=\"fulltext-link\">Fig.16</a> shows the CDF and Mean Error for these two algorithms using different databases.\n<div class=\"figure figure-full\" id=\"fig16\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang16ab-2939545-large.gif\" data-fig-id=\"fig16\"><img src=\"\" data-src-img=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang16ab-2939545-small.gif\" alt=\"FIGURE 16. - Evaluating improved WKNN using different database. (a) is using a database containing 40 virtual RPs. (b) is using a database containing 400 virtual RPs.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 16. </b><fig><p>Evaluating improved WKNN using different database. (a) is using a database containing 40 virtual RPs. (b) is using a database containing 400 virtual RPs.</p></fig></div><p class=\"links\"><a href=\"/document/8825770/figures\" class=\"all\">Show All</a></p></div></p><p class=\"has-inline-formula\">From <a ref-type=\"fig\" anchor=\"fig16\" class=\"fulltext-link\">Fig.16</a>, we can see that the improved algorithm perform better when we use the sparse database. In sparse database, the average distance from the testing node to the nearby RPs is large than that in dense nodes. But the number of training RPs is limited, and we set <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\varepsilon ^{(1) }=\\varepsilon ^{(2) }=0.5$\n</tex-math></inline-formula>. As a result, we have more possibility to select the more reliable data in sparse database.</p><p>When we use the sparse database for positioning, the mean error for the standard algorithm is 2.2479m, while the improved algorithm is 2.1471m. The positioning accuracy has been improved by the proposed algorithm. When we use the dense database, the positioning accuracy drops down as illustrated in <a ref-type=\"fig\" anchor=\"fig16\" class=\"fulltext-link\">Fig. 16(b)</a>.</p></div><div class=\"section_2\" id=\"sec3d\"><h3>D. Evaluating HPA</h3><div class=\"section_2\" id=\"sec3d1\"><h4>1) Using Sparse Training Database</h4><p>Training and updating a low density of training database is much easier than a dense one. Here we evaluate HPA using the low density of training database.</p><p class=\"has-inline-formula\">In the Simulation, we set <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\rho _{tr}$\n</tex-math></inline-formula> increases from 0.01(8 RPs in <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$800 m^{2}$\n</tex-math></inline-formula> area) to 0.1(80 RPs in <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$800 m^{2}$\n</tex-math></inline-formula> area), and the RPs in <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\rho _{tr}$\n</tex-math></inline-formula> are selected randomly from <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB$\n</tex-math></inline-formula>. In HPA, we create the database with only two levels using GP, LGP and LDPL, respectivily. <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\rho ^{(1) } = 0.05$\n</tex-math></inline-formula>, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\rho ^{(2) } = 0.5$\n</tex-math></inline-formula>, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\lambda ^{(1) }=\\lambda ^{(2) }=1.25$\n</tex-math></inline-formula>, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\varepsilon ^{(1) } = \\varepsilon ^{(2) } = 0.5$\n</tex-math></inline-formula>. In LGP, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$L=5$\n</tex-math></inline-formula>. In the standard WKNN, we use <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB_{tr}$\n</tex-math></inline-formula> for positioning. And we set <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$K=3$\n</tex-math></inline-formula> both in standard and improved WKNN. For each <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\rho _{tr}$\n</tex-math></inline-formula>, we simulate 800 times. In each simulation, we test 2000 positioning instances. In each positioning instances, we use <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB$\n</tex-math></inline-formula> to generate signal strength measurement by adding Gaussian noise <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$N(0,5)$\n</tex-math></inline-formula>. We compare their RMSE, which defined in <a ref-type=\"disp-formula\" anchor=\"deqn16\" href=\"#deqn16\" class=\"fulltext-link\">Equation (16)</a>, and average positioning time for one node.</p><p><a ref-type=\"fig\" anchor=\"fig17\" class=\"fulltext-link\">Fig. 17</a> gives the simulation results.\n<div class=\"figure figure-full\" id=\"fig17\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang17-2939545-large.gif\" data-fig-id=\"fig17\"><img src=\"\" data-src-img=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang17-2939545-small.gif\" alt=\"FIGURE 17. - RMSE of WKNN and HPA using sparse training database.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 17. </b><fig><p>RMSE of WKNN and HPA using sparse training database.</p></fig></div><p class=\"links\"><a href=\"/document/8825770/figures\" class=\"all\">Show All</a></p></div></p><p>In <a ref-type=\"fig\" anchor=\"fig17\" class=\"fulltext-link\">Fig. 17</a>, there are four curves. WKNN means using the standard WKNN algorithm, and the database is the training database. The average RMSE is 4.59. HPA(GP), HPA(LGP), and HPA(LDPL) mean using the HPA algorithm for positioning, and the virtual databases are built using GP, LGP, and LDPL algorithm, respectively. As we can observed from this Figure, HPA(LDPL) performs the worst. The average RMSE is 7.05. HPA(GP) and HPA(LGP) perform nearly the same, the average RMSE is 3.49 and 3.48, respectively. Compared with standard WKNN, the proposed algorithm improves the RMSE for about 24.2%. <a ref-type=\"fig\" anchor=\"fig18\" class=\"fulltext-link\">Fig.18</a> gives the time for locating one node.\n<div class=\"figure figure-full\" id=\"fig18\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang18-2939545-large.gif\" data-fig-id=\"fig18\"><img src=\"\" data-src-img=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang18-2939545-small.gif\" alt=\"FIGURE 18. - Time of WKNN and HPA using sparse training database.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 18. </b><fig><p>Time of WKNN and HPA using sparse training database.</p></fig></div><p class=\"links\"><a href=\"/document/8825770/figures\" class=\"all\">Show All</a></p></div></p><p>In <a ref-type=\"fig\" anchor=\"fig18\" class=\"fulltext-link\">Fig.18</a>, we find that WKNN cost least time, this is because there are less RPs for positioning. HPA(LDPL) cost the most time, this is because in the first stage, the possible region is very large. As a result, in the second stage, the algorithm has to search in a large database. HPA(GP) and HPA(LGP) cost nearly the same. When the training database\u2019s density is about 0.1, WKNN, HPA(GP) and HPA(LGP) cost the same time. But in <a ref-type=\"fig\" anchor=\"fig17\" class=\"fulltext-link\">Fig.17</a>, we can see that HPA(GP) and HPA(LDPL) have less RMSE. And in <a ref-type=\"fig\" anchor=\"fig7\" class=\"fulltext-link\">Fig.7(b)</a>, we see that GP cost far more time for building the virtual database. These result means the proposed algorithm performs the best when the training database is sparse.</p></div><div class=\"section_2\" id=\"sec3d2\"><h4>2) Using Dense Training Database</h4><p class=\"has-inline-formula\">Assuming we have a dense training database <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB_{tr}$\n</tex-math></inline-formula>. For comparing WKNN and HPA, we assumes <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\rho _{tr}$\n</tex-math></inline-formula> varies from 0.1 to 1. The RPs in the training database are selected randomly from <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$DB$\n</tex-math></inline-formula>. All the other parameters are set the same as the previous section. <a ref-type=\"fig\" anchor=\"fig19\" class=\"fulltext-link\">Fig. 19</a> gives the simulation results.\n<div class=\"figure figure-full\" id=\"fig19\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang19-2939545-large.gif\" data-fig-id=\"fig19\"><img src=\"\" data-src-img=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang19-2939545-small.gif\" alt=\"FIGURE 19. - RMSE of WKNN and HPA using dense training database.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 19. </b><fig><p>RMSE of WKNN and HPA using dense training database.</p></fig></div><p class=\"links\"><a href=\"/document/8825770/figures\" class=\"all\">Show All</a></p></div></p><p>In <a ref-type=\"fig\" anchor=\"fig19\" class=\"fulltext-link\">Fig. 19</a>, all the four curves mean the same with <a ref-type=\"fig\" anchor=\"fig17\" class=\"fulltext-link\">Fig.17</a>, but here we use more dense training database. As illustrated in <a ref-type=\"fig\" anchor=\"fig19\" class=\"fulltext-link\">Fig.19</a>, HPA(LDPL) performs the worst, the average RMSE is 4.68. Followed by the standard WKNN algorithm, while the average RMSE is 3.22. HPA(GP) and HPA(LGP) performs nearly the same, the average RMSE is 2.874 and 2.873, respectively. The performance has been improved for about 10.8%. <a ref-type=\"fig\" anchor=\"fig20\" class=\"fulltext-link\">Fig.20</a> is the time for locating one node.\n<div class=\"figure figure-full\" id=\"fig20\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang20-2939545-large.gif\" data-fig-id=\"fig20\"><img src=\"\" data-src-img=\"/mediastore_new/IEEE/content/media/6287639/9668973/8825770/chang20-2939545-small.gif\" alt=\"FIGURE 20. - Time of WKNN and HPA using dense training database.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 20. </b><fig><p>Time of WKNN and HPA using dense training database.</p></fig></div><p class=\"links\"><a href=\"/document/8825770/figures\" class=\"all\">Show All</a></p></div></p><p class=\"has-inline-formula\">In <a ref-type=\"fig\" anchor=\"fig20\" class=\"fulltext-link\">Fig.20</a>, the time for WKNN increase with <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\rho _{tr}$\n</tex-math></inline-formula>, this is because the algorithm has to search in a increasing scale database. But the time for HPA(LDPL) decrease with <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\rho _{tr}$\n</tex-math></inline-formula>, this is because more training RPs are introduced as the increase of <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\rho _{tr}$\n</tex-math></inline-formula>, where <a ref-type=\"fig\" anchor=\"fig12\" class=\"fulltext-link\">Fig.12</a> gives the result. HPA(GP) and HPA(LGP) cost the same. But <a ref-type=\"fig\" anchor=\"fig7\" class=\"fulltext-link\">Fig.7(b)</a> tells us that GP cost far more time for building the virtual database than LGP. These result also means the proposed algorithm performs the best when the training database is dense.</p><p>In this subsection, we prove that the proposed algorithm performs better both using sparse and dense training database.</p></div></div></div>\n<div class=\"section\" id=\"sec4\"><div class=\"header article-hdr\"><div class=\"kicker\">\n                                SECTION IV.</div><h2>Conclusion and Future Works</h2></div><p>Wireless fingerprint technique has the advantage of low deployment cost, supply for reasonable accuracy and easily to be applied to mobile devices. As a result, fingerprinting has attracted a lot of attentions. The positioning accuracy of fingerprint technique is highly dependent on the density of RPs in the fingerprint database. However, constructing a fingerprint database, with high density fingerprint samples, is labor-intensive or impossible in some cases. And even if it was possible to get a high density of fingerprint database, data retrieve from the large database is time consuming, and the database has to be updated as the environment changes.</p><p>For these problems in fingerprinting, we introduce the DLOD(Discrete Level of Detail) from computer graphics to the fingerprint localization problem to propose HPA. This algorithm can be applied to the both high and low density of training database.</p><p>In HPA, we first propose MDA to transform the different density of training database into uniformly distributed databases, which contain different density of sub-databases. And then, we propose LGP to estimate the RSS values for all the virtual RPs. The higher level built with low density of fingerprints gives coarse estimation, while the lower level contains dense data to provide fine estimation. There are two advantages in HPA. Firstly, the time for positioning is reduced. This is because, in HPA, we only search the matched reference points in a small database, instead of a large database. Secondly, the positioning accuracy is increased. This is because LGP will supply more reference points for positioning.</p><p>Simulation results show that when we have a dense training database, the positioning accuracy can be improved for about 10.8%. And when the training database contains low density fingerprints, the positioning accurate can be improved for about 24.2%. The results also imply us that we can select the RPs for training database based on MDA.</p><p>This algorithm can be applied to both high and low density training database, need no more specialized hardware, and can reuse the existing Wi-Fi infrastructure and fingerprint database, implying it\u2019s robust for daily used.</p><p>Our future work is concentrate on building a larger experiment environment to test our algorithm, and more levels will be tested.</p></div>\n</div></div></response>\n"
}