{
    "abstract": "Interpretation of seismic structural traps for accurate hydrocarbon reservoirs characterization is a challenging task. Seismic interpreters learn to accurately delineate subsurface structures after going through a lengthy process of training and expertise-acquiring that is challenging and time-consuming. In this paper, we propose a novel semantic segmentation model for salt domes and faults identi...",
    "articleNumber": "9290013",
    "articleTitle": "Robust Concurrent Detection of Salt Domes and Faults in Seismic Surveys Using an Improved UNet Architecture",
    "authors": [
        {
            "preferredName": "Mustafa Alfarhan",
            "normalizedName": "M. Alfarhan",
            "firstName": "Mustafa",
            "lastName": "Alfarhan",
            "searchablePreferredName": "Mustafa Alfarhan",
            "id": 37088348002
        },
        {
            "preferredName": "Mohamed Deriche",
            "normalizedName": "M. Deriche",
            "firstName": "Mohamed",
            "lastName": "Deriche",
            "searchablePreferredName": "Mohamed Deriche",
            "id": 37270790800
        },
        {
            "preferredName": "Ahmed Maalej",
            "normalizedName": "A. Maalej",
            "firstName": "Ahmed",
            "lastName": "Maalej",
            "searchablePreferredName": "Ahmed Maalej",
            "id": 38193736800
        }
    ],
    "doi": "10.1109/ACCESS.2020.3043973",
    "publicationTitle": "IEEE Access",
    "publicationYear": "2022",
    "publicationVolume": null,
    "publicationIssue": null,
    "volume": "10",
    "issue": null,
    "documentLink": "/document/9290013/",
    "xml": "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<response><accessType>CCBY - IEEE is not the copyright holder of this material. Please follow the instructions via https://creativecommons.org/licenses/by/4.0/ to obtain full-text articles and stipulations in the API documentation.</accessType><div id=\"BodyWrapper\" class=\"ArticlePage\" xmlns:ieee=\"http://www.ieeexplore.ieee.org\"><div id=\"article\">\n<div class=\"section\" id=\"sec1\"><div class=\"header article-hdr\"><div class=\"kicker\">\n                                SECTION I.</div><h2>Introduction</h2></div><p>Interpretation of seismic records is a crucial task for understanding and analyzing geological information about subsurface structures. Seismic interpretation is a workflow that is traditionally undertaken within a collaborative work involving domain experts (i.e. geologists, geophysicists, geoscientists, etc) and is normally done interactively on robust interpretation workstations. These workstations are sets of high-powered computers and software tools, meant to assist interpreters with storing, rendering, and analyzing seismic images. The main goal of seismic interpretation is to accurately identify geological structures from seismic surveys. Such structures include salt domes, faults, unconformities, horizons, facies, and gas chimneys, to name a few. Seismic hazard analysis, natural resources exploration, hydrocarbon reservoir characterization, and depositional environments understanding, are some of the broad range applications of seismic interpretation <a ref-type=\"bibr\" anchor=\"ref1\" id=\"context_ref_1_1\" data-range=\"ref1\">[1]</a>.</p><p>Even though the process of seismic interpretation is computer-aided, it still requires many hours of manual interpretation including visualizing, editing, picking, and labeling different seismic features, along with using distinct marks (or colors) on a slice-by-slice basis. The difficulty of seismic interpretation is compounded by successive and iterative processes of manual corrections/modifications to guarantee acceptable seismic velocity models that are compliant with geological and geophysical knowledge. Being time-consuming, labor-intensive, and subject to prediction biases, plenty of efforts have been put into developing automated seismic interpretation tools.</p><p>A variety of approaches have been developed for seismic interpretation automation over the past two decades. These approaches can, generally, be classified from three perspectives, namely the seismic data modality, seismic event entity, and feature extraction methodology. From the first perspective, approaches either deal with 2D seismic sections (or slices) w.r.t. a specific acquisition direction (i.e. in-line, cross-line or time-line), or with 3D seismic volumes resulting from a combination (or stack) of 2D seismic sections. From the second perspective, a large majority of approaches address a single seismic event detection at a time, with some using diverse texture and even quality metrics for seismic multi-event identification <a ref-type=\"bibr\" anchor=\"ref2\" id=\"context_ref_2_1\" data-range=\"ref2 ref3 ref4 ref5 ref6\">[2]</a>\u2013\u200b<a ref-type=\"bibr\" anchor=\"ref6\" id=\"context_ref_6_1\" data-range=\"ref2 ref3 ref4 ref5 ref6\">[6]</a>. From the third perspective, approaches can be categorized into handcrafted feature-based and DL feature-based. In this work, we propose a new approach for seismic interpretation using a deconvolutional neural network (DCNN). We focus on the challenging concurrent detection of salt bodies and faults from 2D seismic sections using real-world data from the Netherlands offshore F3 block in the North Sea.</p><p>Currently, seismic interpreters are more than ever faced with increasingly larger seismic data volumes and continually dealing with tight deadlines. Thus, global and integrated solutions are needed to automate the seismic interpretation process. Data-driven solutions capable of exploiting the full potential of the challenging seismic <i>big data</i> and speed up workflows while guaranteeing high interpretation accuracy <a ref-type=\"bibr\" anchor=\"ref7\" id=\"context_ref_7_1\" data-range=\"ref7\">[7]</a>.</p><p>Recent years have witnessed the rapid development of deep neural networks (DNN), resulting in significant performance improvement, and great success in numerous computer vision and pattern recognition tasks <a ref-type=\"bibr\" anchor=\"ref8\" id=\"context_ref_8_1\" data-range=\"ref8\">[8]</a>, including image classification, segmentation, and enhancement <a ref-type=\"bibr\" anchor=\"ref9\" id=\"context_ref_9_1\" data-range=\"ref9\">[9]</a>, <a ref-type=\"bibr\" anchor=\"ref10\" id=\"context_ref_10_1\" data-range=\"ref10\">[10]</a>, object detection <a ref-type=\"bibr\" anchor=\"ref11\" id=\"context_ref_11_1\" data-range=\"ref11\">[11]</a>, and so on. The overwhelming efficiency of these techniques triggered the interest of researchers in developing robust seismic interpretation by leveraging the power of DNNs to solve problems associated with seismic surveys understanding, modeling, and interpretation.</p><p>This work is another attempt in this direction and from a new perspective. The novelty of the proposed approach resides in solving the problem of multiple seismic events detection using a hybrid DL architecture. Here, we focus on analyzing complex seismic structures, involving salt domes and faults, both known for being reliable hydrocarbon indicators. These are very challenging seismic structures, due to the weak and chaotic reflection patterns of salt deposit, the varying geometry and distribution of faults, and the complicated wavefield behavior involved in these structures. The primary objective of this work is to concurrently identify faults and salt domes using an improved deep convolutional encoder-decoder architecture, capable of performing a pixel-based prediction on seismic sections to determine whether a pixel is a fault, salt, or none of these. The main challenges encountered within this study involve the following issues: 1) how to deal with the complexity of remote sensing data types such as seismic profile records, which fundamentally differ from natural images, and where the signal to noise ratio (SNR) is quite low. 2). What will be the intuition behind building a task-oriented DL architecture for semantic segmentation of multiple classes of seismic events? 3) How to encounter the problem of insufficient quantity of labeled samples despite the availability of massive seismic data and large scale seismic volumes.</p><p>The main contributions of this paper can be summarized as follows:\n<ul style=\"list-style-type:disc\"><li><p>The accurate detection of multiple seismic structures in a concurrent scenario using an improved DCNN model for semantic segmentation.</p></li><li><p>The leverage of transfer learning, using pre-trained models on natural images, onto the context of seismic image analysis and interpretation.</p></li></ul></p><p>The remainder of the paper is organized as follows. Related works for seismic interpretation of salt and fault structures are presented in <a ref-type=\"sec\" anchor=\"sec2\" class=\"fulltext-link\">Section II</a>. In <a ref-type=\"sec\" anchor=\"sec3\" class=\"fulltext-link\">Section III</a>, we introduce the workflow of the proposed deep encoder-decoder network for relevant seismic features segmentation, where different UNet variants are employed to address concurrent detection of salt domes and faults in real-world seismic data. In <a ref-type=\"sec\" anchor=\"sec4\" class=\"fulltext-link\">Section IV</a>, comprehensive experiments are presented and detection results are obtained to assess the performance of the proposed approach. Both qualitative and quantitative evaluations are reported with a comparison to a recently developed approach dealing with multi-event detection. Lastly, the conclusion is reported in <a ref-type=\"sec\" anchor=\"sec5\" class=\"fulltext-link\">Section V</a>.</p></div>\n<div class=\"section\" id=\"sec2\"><div class=\"header article-hdr\"><div class=\"kicker\">\n                                SECTION II.</div><h2>Related Work</h2></div><p>In this section, we present an overview of previous works on seismic interpretation. We propose a two-fold categorization; first, we review handcrafted-based methods; then we give an overview of DL-based methods.</p><div class=\"section_2\" id=\"sec2a\"><h3>A. Handcrafted Feature-Based Methods</h3><p>In the literature of salt domes and faults interpretation, the majority of approaches were applied to 2D seismic sections using well-established feature extraction methods. Basic edge-detection techniques are primitive, but still being in use, for simplistic seismic interpretation. These techniques can be classified into two families; coherency-based and differencing-based algorithms. Coherency metric checks similarity/dissimilarity between adjacent seismic traces and can be calculated using different explicit formulations such as cross-correlation, semblance, variance, eigen-structure analysis and gradient structural tensor (GST) <a ref-type=\"bibr\" anchor=\"ref12\" id=\"context_ref_12_2a\" data-range=\"ref12\">[12]</a>.</p><p>In contrast, differencing-based algorithms detect discontinuities through differencing amplitude attributes of adjacent seismic traces using operator-based edge detection techniques, such as Sobel, Robert, Prewitt, and Canny <a ref-type=\"bibr\" anchor=\"ref3\" id=\"context_ref_3_2a\" data-range=\"ref3\">[3]</a>. Wu and Hale <a ref-type=\"bibr\" anchor=\"ref4\" id=\"context_ref_4_2a\" data-range=\"ref4\">[4]</a> were among the first to work on the problem of multiple geologic structures detection and interpretation. Fault, unconformity and horizon surfaces were extracted automatically from a single 3D seismic volume. Seismic attributes estimated from differencing seismic amplitudes, and seismic normal vector fields are then used to compute fault and unconformity likelihoods, respectively. Unfaulting and flattening processes are conducted for straightforward extraction of horizons. Most of the processing was achieved by solving partial differential equations.</p><p>Along with edge detection techniques, we can distinguish other engineered features such as geometric, texture and graph -based features. Geometric features are obtained by quantifying geometric variations of seismic reflectors using reflector curvature or flexure. Textural features are rather difficult and challenging to extract, compared to other types of handcrafted features. They are based on statistical analysis, where the spatial distribution of intensity levels in a pixels vicinity is estimated. The relationships between neighboring pixels are evaluated w.r.t. the corresponding gray level and spatial arrangement, so as to decide if they form one and the same region of interest, or not. Different texture measures are proposed directionality, smoothness and edge content in <a ref-type=\"bibr\" anchor=\"ref13\" id=\"context_ref_13_2a\" data-range=\"ref13\">[13]</a>, gray-level co-occurrence matrix (GLCM) contrast and homogeneity <a ref-type=\"bibr\" anchor=\"ref14\" id=\"context_ref_14_2a\" data-range=\"ref14\">[14]</a>, gradient of texture (GoT) <a ref-type=\"bibr\" anchor=\"ref15\" id=\"context_ref_15_2a\" data-range=\"ref15\">[15]</a>, code-book based learning <a ref-type=\"bibr\" anchor=\"ref16\" id=\"context_ref_16_2a\" data-range=\"ref16\">[16]</a>, and seismic saliency <a ref-type=\"bibr\" anchor=\"ref17\" id=\"context_ref_17_2a\" data-range=\"ref17\">[17]</a>. Despite being widely used in remotely sensed data, texture-based techniques suffer from the problem of finding line-like edges when dealing with spatial resolution statistics.</p><p>As for graph-based features, they were first applied in <a ref-type=\"bibr\" anchor=\"ref18\" id=\"context_ref_18_2a\" data-range=\"ref18\">[18]</a> to generate mesh representation of seismic images. Inspired by this later work, in <a ref-type=\"bibr\" anchor=\"ref19\" id=\"context_ref_19_2a\" data-range=\"ref19\">[19]</a>, the authors applied the normalized cuts image segmentation (NCIS) technique and validated the successful use of graph-based representation for seismic interpretation.</p><p>Even though designed with expert knowledge, engineered feature extraction methods are unable to fully describe seismic objects of interest and exploit, to the fullest extent, greater value from complex and noise-contaminated real-world data. Besides, most of these approaches address single-event interpretation tasks, while in a real-world scenario, seismic data are most likely to contain multiple events and variant seismic features.</p><p>Unfortunately, the aforementioned methods remain either trapped in the experimental phase and impractical for industrial deployment, or serving as a suite of computer-aided tools to assist seismic interpreters. Moreover, the proliferation of large three-dimensional (3D) seismic surveying technologies with a large scale coverage, relative to basin size, has allowed for capturing a massive amount of high-resolution seismic data. This has revealed the weaknesses of handcrafted features based methods. Usually not robust and computationally intensive, these methods struggle in achieving high accuracy when dealing with such large scale data.</p></div><div class=\"section_2\" id=\"sec2b\"><h3>B. Dl-Based Methods</h3><p>The DL paradigm brings data-driven technologies to the next level by providing powerful tools that are capable of automatically extracting extremely detailed features from an enormous amount of data. The effectiveness of DL-based methods has been shown in different applications of seismic data analysis. In an interesting investigation by Di <i>et al.</i> <a ref-type=\"bibr\" anchor=\"ref20\" id=\"context_ref_20_2b\" data-range=\"ref20\">[20]</a>, a proof-of-principle study is conducted with focusing on the contributing factors to the superiority of CNN-based methods, over traditional techniques, in detecting important seismic structures. In the study, two key strengths are highlighted, the ability to generate a rich suite of feature maps, and the patch-based encoding of seismic reflection patterns to map seismic signals into targeted seismic structures.</p><p>In what follows, we give an overview of main DL approaches related to seismic interpretation while sundering them into two families; CNN-based <a ref-type=\"bibr\" anchor=\"ref21\" id=\"context_ref_21_2b\" data-range=\"ref21 ref22 ref23 ref24 ref25\">[21]</a>\u2013\u200b<a ref-type=\"bibr\" anchor=\"ref25\" id=\"context_ref_25_2b\" data-range=\"ref21 ref22 ref23 ref24 ref25\">[25]</a> and DCNN-based <a ref-type=\"bibr\" anchor=\"ref26\" id=\"context_ref_26_2b\" data-range=\"ref26 ref27 ref28 ref29 ref30\">[26]</a>\u2013\u200b<a ref-type=\"bibr\" anchor=\"ref30\" id=\"context_ref_30_2b\" data-range=\"ref26 ref27 ref28 ref29 ref30\">[30]</a>. Under the first type of approaches, the interpretation task is a classification-oriented problem, whereas, under the second type, it is a segmentation-oriented one. The equivalence relation between image segmentation and pixel-level classification legitimates the adopted problem solving direction.</p><div class=\"section_2\" id=\"sec2b1\"><h4>1) CNN-Based Approaches</h4><p>Waldeland <i>et al.</i> <a ref-type=\"bibr\" anchor=\"ref21\" id=\"context_ref_21_2b1\" data-range=\"ref21\">[21]</a> work appears to be one of the early attempts at applying CNNs to learn features from seismic data for salt bodies delineation. A simple CNN architecture is proposed, built using 5 convolutional layers and one fully-connected layer and a two-node softmax for salt or non-salt pixel classification. By using only one manually labeled inline slice, a set of small cubes, centered around the corresponding pixels, are selected to train the proposed model. Only qualitative assessment of the salt detection is reported using an illustration of pixel-wise classification results for a few selected sections of the Netherlands off-shore F3 block seismic volume.</p><p>Xiong <i>et al.</i> <a ref-type=\"bibr\" anchor=\"ref24\" id=\"context_ref_24_2b1\" data-range=\"ref24\">[24]</a> applied CNN for fault mapping within a 3D seismic volume. Fault probability cube is generated using the CNN model composed of only 2 convolutional layers, two fully-connected layers and a two-node softmax classifier (i.e. fault prediction). Only three seismic slices forming orthogonal cross-sections are used to feed the 3 channels input layer. Fault or non fault prediction is set to be associated with the cubes\u2019 central point. Real data from 8 annotated seismic cubes are used to generate the training data set with one holdout for validation. To test the model both synthetic and real seismic data are used. The fault probability cube imaging, generated by the proposed model, highlights seismic faults and shows off discontinuities more clearly compared to the traditional coherence cube method <a ref-type=\"bibr\" anchor=\"ref31\" id=\"context_ref_31_2b1\" data-range=\"ref31\">[31]</a>. Wu <i>et al.</i> <a ref-type=\"bibr\" anchor=\"ref32\" id=\"context_ref_32_2b1\" data-range=\"ref32\">[32]</a> used a CNN-based pixel-wise classification method not only to predict fault probability, but also to estimate fault orientations (i.e. dips) simultaneously. To train and validate the proposed CNN model, the authors also developed a well-established workflow to automatically generate synthetic 2D seismic data and their corresponding labeling. The proposed model outperforms conventional methods when tested on real seismic data. Inspired by the latter work, Zheng <i>et al.</i> <a ref-type=\"bibr\" anchor=\"ref23\" id=\"context_ref_23_2b1\" data-range=\"ref23\">[23]</a> used two CNN models for predicting fault presence and its orientation (i.e. dip and azimuth attributes) simultaneously. They demonstrated that CNN models trained on synthetic data can be used efficiently for fault predictions on field data.</p></div><div class=\"section_2\" id=\"sec2b2\"><h4>2) DCNN-Based Approaches</h4><p class=\"has-inline-formula\">Shi <i>et al.</i> <a ref-type=\"bibr\" anchor=\"ref26\" id=\"context_ref_26_2b2\" data-range=\"ref26\">[26]</a> considered salt body detection as semantic image segmentation problem. Inspired by both Segnet <a ref-type=\"bibr\" anchor=\"ref33\" id=\"context_ref_33_2b2\" data-range=\"ref33\">[33]</a> and UNet <a ref-type=\"bibr\" anchor=\"ref34\" id=\"context_ref_34_2b2\" data-range=\"ref34\">[34]</a>, they developed a DL encoder-decoder architecture for an end-to-end salt body detection. Zeng <i>et al.</i> <a ref-type=\"bibr\" anchor=\"ref27\" id=\"context_ref_27_2b2\" data-range=\"ref27\">[27]</a> applied the state-of-art UNet model, along with the residual learning framework ResNet for salt body identification. Alaudah <i>et al.</i> <a ref-type=\"bibr\" anchor=\"ref28\" id=\"context_ref_28_2b2\" data-range=\"ref28\">[28]</a> proposed a deconvolutional network for various seismic interpretation tasks including salt domes and faults. Di <i>et al.</i> <a ref-type=\"bibr\" anchor=\"ref30\" id=\"context_ref_30_2b2\" data-range=\"ref30\">[30]</a> proposed a real-time seismic interpretation approach using a DNN model. The method is capable of accurately identifying several seismic features simultaneously. Karchevskiy <i>et al.</i> <a ref-type=\"bibr\" anchor=\"ref29\" id=\"context_ref_29_2b2\" data-range=\"ref29\">[29]</a> got into the <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$27^{th}$\n</tex-math></inline-formula> place in Kaggle competition for salt identification using UNet variant and fine-tuned the encoder based on the pre-trained ResNeXt50 model. More recently, Li <i>et al.</i> <a ref-type=\"bibr\" anchor=\"ref35\" id=\"context_ref_35_2b2\" data-range=\"ref35\">[35]</a> used the UNet for seismic fault detection and highlighted the efficiency of such a model in achieving good performance without any issues regarding insufficient training data. To perform 3D fault segmentation, Wu <i>et al.</i> <a ref-type=\"bibr\" anchor=\"ref36\" id=\"context_ref_36_2b2\" data-range=\"ref36\">[36]</a> proposed FaultSeg3D, a simplified version of UNet, where a set of 15 convolutional layers are used instead of the original 23 of UNet, and also a reduced number of feature channels per layer. Although trained on synthetic data, the FaultSeg3D model showed high efficiency in recognizing faults in several seismic data volumes acquired at different surveys. A thorough comparison against several conventional methods is reported in terms of both qualitative illustrations and quantitative measurement to demonstrate the superiority of the FaultSeg3D in achieving state-of-the-art results.</p><p>Very limited number of works have addressed the multiple seismic structures detection problems. To handle this particular challenging task, the proposed approaches either tackle the issue from an image processing perspective using complex engineered features <a ref-type=\"bibr\" anchor=\"ref4\" id=\"context_ref_4_2b2\" data-range=\"ref4\">[4]</a>, <a ref-type=\"bibr\" anchor=\"ref5\" id=\"context_ref_5_2b2\" data-range=\"ref5\">[5]</a>, or employ a simple deconvolutional network architecture with poor performance appraisal when it comes to detection results <a ref-type=\"bibr\" anchor=\"ref28\" id=\"context_ref_28_2b2\" data-range=\"ref28\">[28]</a>.</p><p>Since UNet was introduced by Ronneberger <i>et al.</i> <a ref-type=\"bibr\" anchor=\"ref34\" id=\"context_ref_34_2b2\" data-range=\"ref34\">[34]</a> for medical image segmentation, it has become the go-to architecture for segmentation tasks due to its simplicity and success in tackling diverse segmentation problems. In this work, we employ the UNet model for concurrent detection of salt domes and faults in real seismic data. The UNet has become the benchmark approach for semantic segmentation which led us to select it for tackling our problem over other semantic segmentation deep learning based approaches. In addition, the simple design of the UNet allows for more customization flexibility, which we need to develop our own workflow. And most importantly, the UNet is suitable for small training datasets. Also, since the UNet is an encoder-decoder network type, we exploit transfer learning using two different encoders (VGG19 <a ref-type=\"bibr\" anchor=\"ref37\" id=\"context_ref_37_2b2\" data-range=\"ref37\">[37]</a> and ResNet34 <a ref-type=\"bibr\" anchor=\"ref38\" id=\"context_ref_38_2b2\" data-range=\"ref38\">[38]</a>), that have been trained on a substantial natural images database. The use of pre-trained encoders improved the detection accuracy of our DL network and led to excellent accuracy despite the fact that we only have a small number of labeled seismic images. Moreover, we show the benefits of using transfer learning by applying pre-trained networks compared with the ones trained from scratch.</p></div></div></div>\n<div class=\"section\" id=\"sec3\"><div class=\"header article-hdr\"><div class=\"kicker\">\n                                SECTION III.</div><h2>Methodology</h2></div><p>Building a successful DL workflow requires the availability of an adequate amount of labeled data so that the network can learn the relevant features to the problem at hand. The availability of diverse DL frameworks and various libraries facilitate the use of off-the-shelf CNN architectures as well as selecting best practices in the field. However, the bottleneck, most of the time, for a high performing model is the lack of labeled data. For seismic applications, there are several publicly available datasets such as the Netherland F3 dataset <a ref-type=\"bibr\" anchor=\"ref39\" id=\"context_ref_39_3\" data-range=\"ref39\">[39]</a> and the SEAM Phase I dataset <a ref-type=\"bibr\" anchor=\"ref40\" id=\"context_ref_40_3\" data-range=\"ref40\">[40]</a>. Nonetheless, the seismic interpretation field is actually facing shortage of labeled data, since it requires experts\u2019 effort, time and knowledge, to acquire. Researchers mainly dealt with this problem in 4 different ways: <a ref-type=\"disp-formula\" anchor=\"deqn1\" href=\"#deqn1\" class=\"fulltext-link\">(1)</a> Acquiring a few manually labeled sections, (2) Labeling data using conventional image processing techniques, (3) Synthesizing data which labeling can be derived automatically, or (4) using a small set of labeled data to train a weakly supervised learning approach for predicting labels of a larger pool of dataset.</p><p>In this experiment, we choose to use a small set of manually labeled sections from the F3 block for the problem of concurrent detection of salt domes and faults in seismic data. <a ref-type=\"fig\" anchor=\"fig1\" class=\"fulltext-link\">Figure 1</a> shows three seismic images from the training data (top row) and their corresponding event labeling (bottom row). From left to right the seismic samples illustrate salt dome, fault, and multiple faults seismic events, respectively.\n<div class=\"figure figure-full\" id=\"fig1\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9290013/deric1-3043973-large.gif\" data-fig-id=\"fig1\"><img src=\"\" data-src-img=\"/mediastore_new/IEEE/content/media/6287639/9668973/9290013/deric1-3043973-small.gif\" alt=\"FIGURE 1. - Illustration of seismic images (first row) and their corresponding manual labeling of the underlying events (second row).\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 1. </b><fig><p>Illustration of seismic images (first row) and their corresponding manual labeling of the underlying events (second row).</p></fig></div><p class=\"links\"><a href=\"/document/9290013/figures\" class=\"all\">Show All</a></p></div></p><div class=\"section_2\" id=\"sec3a\"><h3>A. Proposed Architecture</h3><p class=\"has-inline-formula\">We propose to explore two UNet variants in order to find out which architecture has higher detection accuracy. The two networks have similar decoders, where they contain convolution layers, up-sampling layers, and concatenation layers. The concatenation layers are used to concatenate the output of the up-sampling layers with the feature maps passed from the encoder, along the feature map axis. Each convolution layer is followed by a batch normalization (BN) layer, and a rectified linear units (ReLU) activation layer. The difference between the two networks resides in the encoder. The first DL network employs a VGG19 network as encoder, where successive convolution layers and max-pooling layers are used. The number of filters is doubled after the max-pooling layer and this process is duplicated five times. On the other hand, the second network\u2019s encoder is built using ResNet34, where identity mapping is used to improve the backward flow of the gradient of the error during the training of very deep networks and avoid the vanishing gradient problem <a ref-type=\"bibr\" anchor=\"ref41\" id=\"context_ref_41_3a\" data-range=\"ref41\">[41]</a>. In the ResNet network, a residual block (<a ref-type=\"fig\" anchor=\"fig2\" class=\"fulltext-link\">Figure 2</a>) is used where the input to the block is added to the output after two convolution layers, and passed to the next stage. However, when the input and the output have a different number of feature maps, the input is passed through a <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$1\\times 1$\n</tex-math></inline-formula> convolution layer to match the number of feature maps to that of the output. Therefore, the ResNet34 is built by stacking Residual Blocks.\n<div class=\"figure figure-full\" id=\"fig2\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9290013/deric2-3043973-large.gif\" data-fig-id=\"fig2\"><img src=\"\" data-src-img=\"/mediastore_new/IEEE/content/media/6287639/9668973/9290013/deric2-3043973-small.gif\" alt=\"FIGURE 2. - Residual Blocks 1 and 2 used to build Resnet-Cin is the number of input feature maps and Cout is the number of output feature maps.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 2. </b><fig><p>Residual Blocks 1 and 2 used to build Resnet-<i>Cin</i> is the number of input feature maps and <i>Cout</i> is the number of output feature maps.</p></fig></div><p class=\"links\"><a href=\"/document/9290013/figures\" class=\"all\">Show All</a></p></div></p><p><a ref-type=\"fig\" anchor=\"fig2\" class=\"fulltext-link\">Figure 2</a> shows Residual Blocks 1 and 2 where the first block is used when there is a mismatch between the number of feature maps of the input and output, and the second block is used when there is no such mismatch <a ref-type=\"bibr\" anchor=\"ref38\" id=\"context_ref_38_3a\" data-range=\"ref38\">[38]</a>. <a ref-type=\"fig\" anchor=\"fig3\" class=\"fulltext-link\">Figures 3</a> and <a ref-type=\"fig\" anchor=\"fig4\" class=\"fulltext-link\">4</a> show the proposed architectures, namely UNet-VGG19 and UNet-ResNet34, respectively, which we built for simultaneous salt domes and faults segmentation. The last layer in both networks is a convolution layer with three filters followed by a softmax layer, and where the three channels in the output represent the background, fault, and salt classes, respectively. The fusion of the UNet with either VGG19 or ResNet34 is achieved by substituting the UNet encoder with VGG19 and ResNet34 networks, respectively. However, both CNNs have their fully-connected layers removed, usually used for classification tasks and are not relevant to semantic segmentation ones.\n<div class=\"figure figure-full\" id=\"fig3\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9290013/deric3-3043973-large.gif\" data-fig-id=\"fig3\"><img src=\"\" data-src-img=\"/mediastore_new/IEEE/content/media/6287639/9668973/9290013/deric3-3043973-small.gif\" alt=\"FIGURE 3. - Proposed UNet-VGG19 architecture, numbers in parentheses are height and width of input and number of filters in convolution layer.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 3. </b><fig><p>Proposed UNet-VGG19 architecture, numbers in parentheses are height and width of input and number of filters in convolution layer.</p></fig></div><p class=\"links\"><a href=\"/document/9290013/figures\" class=\"all\">Show All</a></p></div>\n<div class=\"figure figure-full\" id=\"fig4\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9290013/deric4-3043973-large.gif\" data-fig-id=\"fig4\"><img src=\"\" data-src-img=\"/mediastore_new/IEEE/content/media/6287639/9668973/9290013/deric4-3043973-small.gif\" alt=\"FIGURE 4. - Proposed UNet-ResNet34 architecture (numbers in parentheses are height and width of input and number of filters in convolution layer).\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 4. </b><fig><p>Proposed UNet-ResNet34 architecture (numbers in parentheses are height and width of input and number of filters in convolution layer).</p></fig></div><p class=\"links\"><a href=\"/document/9290013/figures\" class=\"all\">Show All</a></p></div></p></div><div class=\"section_2\" id=\"sec3b\"><h3>B. Network Training</h3><p>The UNet-VGG19 and UNet-ResNet34 networks were trained on seismic data from the Netherland F3 block using two methods. The first training method involves random initialization of the weights of the neural networks, which is commonly referred to as training from scratch. The second training method uses the weights of pre-trained encoders as initialization parameters. Then, a fine-tuning process is applied to adjust the weights for our specific task. The pre-trained encoders we used are the VGG19 and ResNet34, which were trained on natural images from the ImageNet dataset <a ref-type=\"bibr\" anchor=\"ref42\" id=\"context_ref_42_3b\" data-range=\"ref42\">[42]</a>. With <i>off-the-shelf</i> pre-trained deep neural network architectures, we can use the attributes that are learned from a huge amount of data, such as the ImageNet dataset, and avoid the need for a large amount of labeled data in our seismic interpretation task.</p><p class=\"has-inline-formula\">Ideally, we want to train deep neural networks with thousands of labeled images. However, we were limited by a small number of seismic labeled images, where both salt domes and faults coexist. The seismic dataset we used contains 61 labeled salt dome images and 43 labeled fault images. Out of the 61 salt images, 49 are used for training and 12 for validation. Similarly, out of the 43 fault images, 35 are used for training and 8 for validation. So, 80% of the salt dome and fault images are used for training and the remaining 20% are held out for validation. The images are rectangular and have different sizes, but neural networks accept a fixed input size. Following the practice in the field, we chose to set the size of the images to be of the power of 2 and to have a square shape. Otherwise, we would have to change the implementation of the networks which would make it difficult to use transfer learning. Thus, the input to the network is chosen to be <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$128\\times 128$\n</tex-math></inline-formula> which is obtained by randomly cropping the input image. Also, the input image pixel values are normalized and the labels are one-hot encoded.</p><p class=\"has-inline-formula\">While carrying out experiments, we noticed that faults are mainly line-like structures that are thin, occupying only one or two pixels in width. Thus, the fault class makes the data highly imbalanced, and the network would be biased toward predicting all samples (pixels) as non-fault. We remedy this class imbalance by manually thickening the faults in the ground truth and by using the balanced cross-entropy loss function. The balanced cross-entropy loss <a ref-type=\"bibr\" anchor=\"ref43\" id=\"context_ref_43_3b\" data-range=\"ref43\">[43]</a> is given by <disp-formula id=\"deqn1\" class=\"display-formula\"><tex-math notation=\"LaTeX\">\\begin{equation*} L=-\\beta \\sum _{i=0}^{i=N}y_{i}\\log (p_{i}) - (1-\\beta) \\sum _{i=0}^{i=N}(1-y_{i})\\log (1-p_{i}) \\tag{1}\\end{equation*}\n</tex-math><span class=\"formula\"><span class=\"link\">View Source</span><img aria-describedby=\"qtip-0\" style=\"display:inline;\" title=\"Right-click on figure or equation for MathML and additional features.\" data-hasqtip=\"0\" class=\"qtooltip moreInfo\" alt=\"Right-click on figure for MathML and additional features.\" src=\"/assets/img/icon.support.gif\" border=\"0\" height=\"20\" width=\"24\"/><span class=\"tex tex2jax_ignore\" style=\"display:none;\">\\begin{equation*} L=-\\beta \\sum _{i=0}^{i=N}y_{i}\\log (p_{i}) - (1-\\beta) \\sum _{i=0}^{i=N}(1-y_{i})\\log (1-p_{i}) \\tag{1}\\end{equation*}\n</span></span></disp-formula> where <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$y$\n</tex-math></inline-formula> is the ground truth label, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$p$\n</tex-math></inline-formula> is the prediction probability, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$N$\n</tex-math></inline-formula> is the number of samples in the image, <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$\\beta =\\sum _{i=0}^{i=N}\\frac {1-y_{i}}{N}$\n</tex-math></inline-formula> is the ratio of the non-fault samples, and <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$(1-\\beta)$\n</tex-math></inline-formula> is the ratio of fault samples.</p></div></div>\n<div class=\"section\" id=\"sec4\"><div class=\"header article-hdr\"><div class=\"kicker\">\n                                SECTION IV.</div><h2>Experimental Results</h2></div><p class=\"has-inline-formula\">First, we pre-process each input image from the North Sea F3 Block by only normalizing the image and then randomly cropping it to a <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$128\\times 128$\n</tex-math></inline-formula> image size. After that, we train 4 DCNN architectures on these samples. Overall, we have 4 training scenarios: 2 U-Net networks trained from scratch, where the first has a VGG19 encoder and the second has a ResNet34 encoder. The other 2 networks, similar to the first two, except that the encoders, this time, are pre-trained on ImageNet. Each network is trained for 100 epochs with a learning rate initialized at 10<sup>-4</sup> and decayed by a factor of 0.5 when the validation accuracy does not improve for successive 5 epochs.</p><p>Unsurprisingly, the pre-trained networks noticeably show better accuracy results compared to the ones trained from scratch. <a ref-type=\"table\" anchor=\"table1\" class=\"fulltext-link\">Table 1</a> summarizes the accuracy rates comparing performances using the pre-trained network against the non-pre-trained ones. For further assessment of the models\u2019 performance, we use the most common evaluation metrics utilized to quantify the accuracy of classification/segmentation models, namely, <i>Precision</i>, <i>Recall</i>, <i>F1-score</i>, and <i>IoU</i>. <a ref-type=\"table\" anchor=\"table2\" class=\"fulltext-link\">Table 2</a> summarizes the evaluation metrics values obtained using the deployed deep networks. Their performance is also compared with the results obtained from the basic UNet model, serving here as a baseline model. Regarding these evaluation metrics measures, the four networks reach high accuracy in detecting the background and salt samples. Nonetheless, it is worth noting that the applied deep models still struggle, to a certain extent, with detecting the fault event. The pre-trained networks, however, show a big improvement in fault detection. This performance improvement is obviously gained from the benefits of incorporating pre-trained CNN models in our proposed deep model, which allowed for the enhancement of our proposed framework with better generalization ability. The incorporation of pre-trained CNN models, in the encoder side of the proposed architecture, brings a deep learning model capable of retrieving low-level features (i.e. primitive features); such as curves, line-segments, and edges, learned from a substantial database of natural images.<div class=\"figure figure-full table\" id=\"table1\"><div class=\"figcaption\"><b class=\"title\">TABLE 1 </b>\nTraining and Validation Accuracies for the Four Networks</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9290013/deric.t1-3043973-large.gif\"><img src=\"\" data-src-img=\"/mediastore_new/IEEE/content/media/6287639/9668973/9290013/deric.t1-3043973-small.gif\" alt=\"Table 1- &#10;Training and Validation Accuracies for the Four Networks\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div><div class=\"figure figure-full table\" id=\"table2\"><div class=\"figcaption\"><b class=\"title\">TABLE 2 </b>\nQuantitative Performance Evaluation of the 5 Different Networks</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9290013/deric.t2-3043973-large.gif\"><img src=\"\" data-src-img=\"/mediastore_new/IEEE/content/media/6287639/9668973/9290013/deric.t2-3043973-small.gif\" alt=\"Table 2- &#10;Quantitative Performance Evaluation of the 5 Different Networks\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div></p><p>The baseline UNet model shows, also, good performance and achieves the highest precision rate in detecting faults, but it misses out on most of the fault structures, as revealed by the low rate of the corresponding recall measure.</p><p>Furthermore, qualitative evaluation of the proposed framework is provided through the visualizations of seismic event class prediction for all proposed networks. <a ref-type=\"fig\" anchor=\"fig5\" class=\"fulltext-link\">Figures 5</a> and <a ref-type=\"fig\" anchor=\"fig6\" class=\"fulltext-link\">6</a> show typical salt dome and fault images, respectively, with class prediction results, along with manual ground truth, and the superposition of both (labeled as overlaid), respectively. We can clearly observe that the 4 networks achieve accurate detection of salt dome events across all sample images. As for faults, the two networks trained from scratch, either missed the fault events or detected them partially. Similarly, UNet shows accurate detection of salt domes, but fails in detecting faults as depicted in <a ref-type=\"fig\" anchor=\"fig7\" class=\"fulltext-link\">Figure 7</a>. On the other hand, the two pre-trained networks have benefited from being trained on the ImageNet, even though it contains natural images, and both networks were able to detect most or all fault samples accurately as shown with the 2 sample fault images in <a ref-type=\"fig\" anchor=\"fig6\" class=\"fulltext-link\">Figure 6</a>. The improved performance of the pre-trained networks suggests that attributes learned from natural images can be transferred to the seismic domain and can be used to obtain high detection accuracy with small size labeled datasets.\n<div class=\"figure figure-full\" id=\"fig5\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9290013/deric5-3043973-large.gif\" data-fig-id=\"fig5\"><img src=\"\" data-src-img=\"/mediastore_new/IEEE/content/media/6287639/9668973/9290013/deric5-3043973-small.gif\" alt=\"FIGURE 5. - Event prediction of the 4 networks for an example of a sample salt dome image.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 5. </b><fig><p>Event prediction of the 4 networks for an example of a sample salt dome image.</p></fig></div><p class=\"links\"><a href=\"/document/9290013/figures\" class=\"all\">Show All</a></p></div>\n<div class=\"figure figure-full\" id=\"fig6\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9290013/deric6ab-3043973-large.gif\" data-fig-id=\"fig6\"><img src=\"\" data-src-img=\"/mediastore_new/IEEE/content/media/6287639/9668973/9290013/deric6ab-3043973-small.gif\" alt=\"FIGURE 6. - Event prediction of the 4 networks for an example of two sample fault images (first 2 rows, left).\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 6. </b><fig><p>Event prediction of the 4 networks for an example of two sample fault images (first 2 rows, left).</p></fig></div><p class=\"links\"><a href=\"/document/9290013/figures\" class=\"all\">Show All</a></p></div>\n<div class=\"figure figure-full\" id=\"fig7\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9290013/deric7-3043973-large.gif\" data-fig-id=\"fig7\"><img src=\"\" data-src-img=\"/mediastore_new/IEEE/content/media/6287639/9668973/9290013/deric7-3043973-small.gif\" alt=\"FIGURE 7. - U-Net prediction for salt on the top and fault at the bottom.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 7. </b><fig><p>U-Net prediction for salt on the top and fault at the bottom.</p></fig></div><p class=\"links\"><a href=\"/document/9290013/figures\" class=\"all\">Show All</a></p></div></p><p class=\"has-inline-formula\">Note that our semantic segmentation model is fed with <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$128\\times 128$\n</tex-math></inline-formula> sub-images generated from the original seismic section using random cropping. This resulted in small geometric variations (position-wise) in the images used for comparison in <a ref-type=\"fig\" anchor=\"fig6\" class=\"fulltext-link\">Figure 6</a>. However, these small variations due to random cropping, do not invalidate the comparison between the networks.</p><p>In <a ref-type=\"fig\" anchor=\"fig6\" class=\"fulltext-link\">Figure 6</a>, we display some failure cases of seismic event detection. The figure shows zoomed regions where the pre-trained ResNet34 failed to accurately detect fault(s) or salt boundaries. We can see that for the salt sample, the network has thickened more the salt boundary. On the other hand, for faults samples, the network struggled to delineate the upper and lower bounds of the fault endpoints, and failed to label these extreme parts as faults. We speculate that a possible cause for such failure may be due to the strategy of random region cropping we adopted for preparing the input data to our deep framework. The lack of large amounts of labeled data with more variance, in the geometry and subsurface conditions, can be another reason for such missed detection. With more labeled sample images, and as we showed in <a ref-type=\"table\" anchor=\"table1\" class=\"fulltext-link\">Tables 1</a> and <a ref-type=\"table\" anchor=\"table1\" class=\"fulltext-link\">1</a>, the proposed architecture is able to learn effectively from the data, and extract the most useful and relevant features to delineate accurately fault and salt boundaries.</p><div class=\"section_2\" id=\"sec4a\"><h3>A. Tests on the Landmass Dataset</h3><p>The sizes of the UNet-VGG19 and the UNet-ResNet34 networks are very large with 29 million parameters for the VGG19 version and 24.5 million parameters for the ResNet34 version. Conversely, the training dataset is relatively small (only 84 images). Therefore, we decided to carry out further testing to ensure that the models are not overfitting and only learning attributes that are useful for seismic data. Moreover, since the networks trained from scratch did not perform well on faults, in what follows, we focus on the test results obtained using the pre-trained networks. We selected the LANDMASS dataset <a ref-type=\"bibr\" anchor=\"ref44\" id=\"context_ref_44_4a\" data-range=\"ref44\">[44]</a> to perform our tests which contains different types of seismic events including salt domes and faults. To evaluate the networks\u2019 prediction performance, we overlay the prediction on the original seismic image for visual inspection. In <a ref-type=\"fig\" anchor=\"fig9\" class=\"fulltext-link\">Figure 9</a>, we show the results for salt domes detection for three images with the prediction for the UNet-VGG19 network on the left and the UNet-ResNet34 on the right as well as for three fault images in <a ref-type=\"fig\" anchor=\"fig10\" class=\"fulltext-link\">Figure 10</a>. In the case of salt examples, both pre-trained networks were able to detect salt domes and delineate salt boundaries accurately, but, in some cases, the UNet-VGG19 cannot distinguish between salt boundaries and faults. Also, the fault detection is accurate but the UNet-VGG19 network is more sensitive to discontinuities, in the sense that it detects more discontinuities as faults that are not faults. Both seismic and natural images contain primitive features (i.e. line-segments, edges, corners, etc) that can be learned as low-level features using DL architectures. VGG and ResNet were trained to detect low level features from substantial natural images databases. Similar low level features exist in seismic images, hence, transfer learning using these networks exploits what has been learned from natural images to help with the detection of seismic events.\n<div class=\"figure figure-full\" id=\"fig8\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9290013/deric8-3043973-large.gif\" data-fig-id=\"fig8\"><img src=\"\" data-src-img=\"/mediastore_new/IEEE/content/media/6287639/9668973/9290013/deric8-3043973-small.gif\" alt=\"FIGURE 8. - Zoomed in portions for 3 sample images showing situations of network\u2019s failure.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 8. </b><fig><p>Zoomed in portions for 3 sample images showing situations of network\u2019s failure.</p></fig></div><p class=\"links\"><a href=\"/document/9290013/figures\" class=\"all\">Show All</a></p></div>\n<div class=\"figure figure-full\" id=\"fig9\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9290013/deric9-3043973-large.gif\" data-fig-id=\"fig9\"><img src=\"\" data-src-img=\"/mediastore_new/IEEE/content/media/6287639/9668973/9290013/deric9-3043973-small.gif\" alt=\"FIGURE 9. - 3 salt test images from the LANDMASS dataset with the predictions using the pre-trained networks- blue, green, and red represent background, fault and salt, respectively.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 9. </b><fig><p>3 salt test images from the LANDMASS dataset with the predictions using the pre-trained networks- blue, green, and red represent background, fault and salt, respectively.</p></fig></div><p class=\"links\"><a href=\"/document/9290013/figures\" class=\"all\">Show All</a></p></div>\n<div class=\"figure figure-full\" id=\"fig10\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9290013/deric10-3043973-large.gif\" data-fig-id=\"fig10\"><img src=\"\" data-src-img=\"/mediastore_new/IEEE/content/media/6287639/9668973/9290013/deric10-3043973-small.gif\" alt=\"FIGURE 10. - 3 fault test images from the LANDMASS dataset with the predictions using the pre-trained networks- blue, green, and red represent background, fault and salt, respectively.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 10. </b><fig><p>3 fault test images from the LANDMASS dataset with the predictions using the pre-trained networks- blue, green, and red represent background, fault and salt, respectively.</p></fig></div><p class=\"links\"><a href=\"/document/9290013/figures\" class=\"all\">Show All</a></p></div></p></div><div class=\"section_2\" id=\"sec4b\"><h3>B. Comparison With Previous Works</h3><p class=\"has-inline-formula\">It is worth noting that very few related works provide quantitative evaluation of their seismic interpretation models. Most approaches do not apply common evaluation metrics, other than accuracy rates, for performance assessment. Experimental outcomes are usually limited to qualitative evaluation through some illustrations of the interpretation results on test data. Moreover, some approaches generated synthetic data to train their models, and reported high performance through very few illustrations of interpretation results on field data. This is mainly due to lack of labeled data. Indeed, as metric formulas involve ratios of prediction and ground truth samples, a sufficient set of labeled data is therefore needed, which is not easily accessible when it comes to seismic data. <a ref-type=\"table\" anchor=\"table3\" class=\"fulltext-link\">Table 3</a> summarizes comparison with several other seismic interpretation approaches. As outlined in the table, the comparison study takes into consideration the approach category (handcrafted or DL-based), the seismic event object of interpretation, the dataset type for training (synthetic or real-world), and eventually the evaluation metrics along with corresponding maximum values. As mentioned before, most proposed approaches tackle one particular seismic event using different state-of-art DL models. Only two approaches consider more than one seismic event, the handcrafted-based work in <a ref-type=\"bibr\" anchor=\"ref45\" id=\"context_ref_45_4b\" data-range=\"ref45\">[45]</a> and <a ref-type=\"bibr\" anchor=\"ref46\" id=\"context_ref_46_4b\" data-range=\"ref46\">[46]</a>. Different metrics were reported in <a ref-type=\"bibr\" anchor=\"ref45\" id=\"context_ref_45_4b\" data-range=\"ref45\">[45]</a>, standard metrics such as IoU and AUC, but also new ones were introduced, such as pixel accuracy (PA), mean intersection over union (MIU), and frequency-weighted intersection over union (FWIU). In the case of <a ref-type=\"bibr\" anchor=\"ref46\" id=\"context_ref_46_4b\" data-range=\"ref46\">[46]</a>, only qualitative evaluation is carried out through visualization of segmentation results on field test data.<div class=\"figure figure-full table\" id=\"table3\"><div class=\"figcaption\"><b class=\"title\">TABLE 3 </b>\nComparison With Previous Works</div><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9290013/deric.t3-3043973-large.gif\"><img src=\"\" data-src-img=\"/mediastore_new/IEEE/content/media/6287639/9668973/9290013/deric.t3-3043973-small.gif\" alt=\"Table 3- &#10;Comparison With Previous Works\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div></div></p><p>For salt domes, the authors in <a ref-type=\"bibr\" anchor=\"ref26\" id=\"context_ref_26_4b\" data-range=\"ref26\">[26]</a> trained a SegNet network using 8 crossline sections on salt dome segmentation and obtained 98.77% accuracy on the training dataset, with no qualitative evaluation on the test dataset. Also, the authors in <a ref-type=\"bibr\" anchor=\"ref27\" id=\"context_ref_27_4b\" data-range=\"ref27\">[27]</a> proposed to use a U-Net+ResNet DL model for salt domes segmentation. They used 2 inline sections for training and 1 section for testing, with no quantitative evaluation of the network\u2019s performance. The approach in <a ref-type=\"bibr\" anchor=\"ref47\" id=\"context_ref_47_4b\" data-range=\"ref47\">[47]</a> for salt dome segmentation trained a basic U-Net on 10 crossline slices, and, again, no qualitative evaluation. As the authors who used SegNet pointed out, SegNet is prone to checkerboard artifacts, which makes it not suitable for small features learning such as faults thin line-segments. Visual comparison of our salt dome detection segmentation against the three aforementioned approaches, shows that we achieve better segmentation results of salt domes, where salt boundaries are accurately traced over the whole image.</p><p>For fault detection, the authors in <a ref-type=\"bibr\" anchor=\"ref49\" id=\"context_ref_49_4b\" data-range=\"ref49\">[49]</a> generated synthetic data to train CNNs, where each image contains straight lines faults. They reported their result for one DL model that gave the best results on synthetic data, and another that gave the best visual results on real-world data. The results for the second CNN on synthetic data are: <i>Accuracy = 0.94</i>, <i>Sensitivity = 0.69</i>, <i>Specificity = 0.99</i>, <i>F1-score = 0.80</i>, and <i>AUC = 0.96</i>. Even though our pre-trained networks have a lower <i>F1-score</i>: <i>0.7712</i> with the VGG19 network and <i>0.6817</i> with the ResNet34 network, our results were obtained on challenging field data. Moreover, using CNN introduces redundancy since the network classifies only one pixel in each run, whereas U-Net classifies all pixels at once in one run. The authors in <a ref-type=\"bibr\" anchor=\"ref35\" id=\"context_ref_35_4b\" data-range=\"ref35\">[35]</a> used a small set of real seismic data to train a U-Net model on fault detection. The best obtained result achieves <i>IoU = 0.500</i>, after a post-processing stage. In contrast, our pre-trained networks reached higher <i>IoU</i> with <i>0.6588</i> with VGG19, and <i>0.5419</i> with the ResNet34 network.</p><p>Lastly, we compare our proposed method with the multiresolution approach developed in <a ref-type=\"bibr\" anchor=\"ref45\" id=\"context_ref_45_4b\" data-range=\"ref45\">[45]</a>. Four multiresolution techniques, based on texture attributes, were used to label seismic structures from the Netherland F3 block. Specifically, the Gaussian pyramid, the Discrete Wavelet Transform, Gabor filters, and the Curvelet Transform. In <a ref-type=\"bibr\" anchor=\"ref45\" id=\"context_ref_45_4b\" data-range=\"ref45\">[45]</a>, the Curvelet Transform provided the best results, with a detection <i>accuracy = 0.7955</i>, <i>IoU = 0.2656</i> for faults, and <i>IoU = 0.5261</i> for salt domes, using only four inline images from the F3 block for validation. Our results are significantly better with <i>IoU = 0.6588</i> compared to <i>0.2656</i> for faults, and <i>IoU = 0.9776</i> compared to <i>0.7953</i> for salt domes using the U-Net-VGG19 pre-trained network. We should note, however, that the authors considered four seismic event classes (chaotic, fault, salt, and other) whereas we considered only three (fault, salt, and background).</p><p class=\"has-inline-formula\"><a ref-type=\"fig\" anchor=\"fig11\" class=\"fulltext-link\">Figure 11</a> shows predictions of our proposed DL models on the same 4 inlines that were used in <a ref-type=\"bibr\" anchor=\"ref45\" id=\"context_ref_45_4b\" data-range=\"ref45\">[45]</a> from the Netherland F3 block (only the bottom section is displayed). Since our network accepts input of size <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$128\\times 128$\n</tex-math></inline-formula>, we divided each image into patches of size <inline-formula class=\"inline-formula\"><tex-math notation=\"LaTeX\">$128\\times 128$\n</tex-math></inline-formula> and passed them to the network one by one. The network was able to detect the salt dome with high accuracy, and also detect most of the faults structures. Our fine-tuned neural networks were able to learn features that are specific to faults and others specific to salt boundaries with hardly any confusion.\n<div class=\"figure figure-full\" id=\"fig11\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9290013/deric11-3043973-large.gif\" data-fig-id=\"fig11\"><img src=\"\" data-src-img=\"/mediastore_new/IEEE/content/media/6287639/9668973/9290013/deric11-3043973-small.gif\" alt=\"FIGURE 11. - Concurrent detection of salt dome and fault events for 4 inline images.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 11. </b><fig><p>Concurrent detection of salt dome and fault events for 4 inline images.</p></fig></div><p class=\"links\"><a href=\"/document/9290013/figures\" class=\"all\">Show All</a></p></div></p><p>Finally, we should note that our proposed framework is well suited for interfacing with user-friendly GUIs to assist interpreters in visualizing different types of events either simultaneously or separately. The interpretation results can also be translated into saliency maps or likelihood maps (i.e. probability maps), with meaningful colormap encoding various seismic events for enhanced visualization. The work discussed here fits well with the efforts put in the industry for optimizing oil and gas exploration processes.</p><p>Over recent years, we have witnessed major partnerships between companies from the oil and gas industry and advanced IT companies joining efforts in developing intelligent systems for enhancing productivity, such as the example of TOTAL (France) and Google Cloud, or ExxonMobil with MIT. Such partnerships turned to powerful AI/ML (Artificial Intelligence / Machine Learning) tools to make the work of seismic volumes interpreters more efficient. Among the different IT companies focusing on developing dedicated tools and systems for 2D and 3D interpretation tasks for industry, we mention Eliis International, PaleoScan, and GVERSE, to mention a few. These companies developed advanced software packages for seismic interpretation with some of the algorithms using diverse Deep Learning networks.</p><p>We should, however, be cautious when using diverse machine learning models, as these can be sensitive to the data distribution. For example, if the distribution of data (i.e. histogram) for the training data (e.g. F3 block) is different from the distribution of data for another dataset (e.g. TGS data) as shown in <a ref-type=\"fig\" anchor=\"fig12\" class=\"fulltext-link\">Figure 12</a>, their performance can be significantly degraded. We show in <a ref-type=\"fig\" anchor=\"fig13\" class=\"fulltext-link\">Figure 13</a> the prediction of UNet-ResNet34 on 3 samples from the TGS dataset with their corresponding ground truth. The first 2 rows show accurate detection compared to the ground truth but the fault channel is activated in a very small portion at the salt boundary. The last row shows an example of a partial failure where the network hardly detects the salt boundary, at the bottom left of the image, and instead a fault channel was activated (in green).\n<div class=\"figure figure-full\" id=\"fig12\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9290013/deric12-3043973-large.gif\" data-fig-id=\"fig12\"><img src=\"\" data-src-img=\"/mediastore_new/IEEE/content/media/6287639/9668973/9290013/deric12-3043973-small.gif\" alt=\"FIGURE 12. - Data distribution (histograms) for a sample from the F3 block (top row) and a smple from the TGS data (bottom row).\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 12. </b><fig><p>Data distribution (histograms) for a sample from the F3 block (top row) and a smple from the TGS data (bottom row).</p></fig></div><p class=\"links\"><a href=\"/document/9290013/figures\" class=\"all\">Show All</a></p></div>\n<div class=\"figure figure-full\" id=\"fig13\"><!--\n          Workaround for combined images.Eg.- 1000116 Fig. 5\n        --><div class=\"img-wrap\"><a href=\"/mediastore_new/IEEE/content/media/6287639/9668973/9290013/deric13-3043973-large.gif\" data-fig-id=\"fig13\"><img src=\"\" data-src-img=\"/mediastore_new/IEEE/content/media/6287639/9668973/9290013/deric13-3043973-small.gif\" alt=\"FIGURE 13. - UNet-ResNet34 prediction on 3 smaple images from the TGS dataset.\"/><div class=\"zoom\" title=\"View Larger Image\"/></a></div><div class=\"figcaption\"><b class=\"title\">FIGURE 13. </b><fig><p>UNet-ResNet34 prediction on 3 smaple images from the TGS dataset.</p></fig></div><p class=\"links\"><a href=\"/document/9290013/figures\" class=\"all\">Show All</a></p></div></p></div></div>\n<div class=\"section\" id=\"sec5\"><div class=\"header article-hdr\"><div class=\"kicker\">\n                                SECTION V.</div><h2>Conclusion</h2></div><p>Concurrent detection of various events from seismic surveys, while extremely important, is very challenging. In this paper, we introduced a novel semantic segmentation workflow for the simultaneous detection of salt domes and faults, using an improved UNet deep network. To further enhance the UNet performance, we exploit transfer learning from two different encoders, namely the VGG19 and ResNet34. The networks are first trained on natural images (ImageNet) before using the fused UNet on seismic surveys. We showed that transfer learning paradigm alleviates the everlasting scarcity problem of labeled seismic data, and is very useful in the case of faults identification, given the limited availability of training data. The knowledge learned from natural images (edges, corners, intensities, etc.) was very useful for identifying the subsurface structures solely from the seismic amplitude attributes.</p><p>Using transfer learning, high delineation accuracy is obtained with reduced execution time, and with using a small amount of labeled training data. Moreover, using transfer learning, we developed a robust model that is not affected by the similarity between different types of discontinuities in noisy seismic data which is improved by utilizing the skip connections strengths of the ResNet model. Comprehensive experiments were conducted through validation and testing on real-world seismic data from the publicly available Netherlands offshore F3 block, LANDMASS, and TGS datasets. Both qualitative and quantitative evaluations confirmed the superior performance achieved by our developed DL workflow, under the challenging scenario of multiple events detection in subsurface surveys.</p></div>\n</div></div></response>\n"
}